{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdCkH2JM07eu"
      },
      "source": [
        "# Quasi-Newton methods: BFGS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9vAduWLjiTl"
      },
      "source": [
        "import numpy as np\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import scipy.optimize\n",
        "import scipy as sp\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# We enable double precision in JAX\n",
        "from jax.config import config\n",
        "config.update(\"jax_enable_x64\", True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQmGG5duO6ig"
      },
      "source": [
        "Consider the [Rosenbrock function](https://en.wikipedia.org/wiki/Rosenbrock_function), that is minimized in $\\mathbf{x} = (1,1,\\dots,1)^T$:\n",
        "\n",
        "$$\\mathcal{L}(\\mathbf{x}) = \\sum_{i=1}^{N-1} [100 (x_{i+1} - x_i^2 )^2 + (1-x_i)^2]$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ybmumhr1z32F"
      },
      "source": [
        "def loss(x):\n",
        "    return sum(100.0 * (x[1:] - x[:-1]**2)**2 + (1 - x[:-1])**2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opnXVnczPDLj"
      },
      "source": [
        "Use `jax` to compute and compile the Rosenbrock function and its gradient."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CEvFRykGQtzx"
      },
      "source": [
        "Implement the BFGS method (with line search) for the minimization of the Rosenbrock function.\n",
        "Set a maximum of 1000 epochs and a stopping tolerance on the gradient eucledian norm of $10^{-8}$. Employ an initial guess for $\\mathbf{x}$ with random numbers in the interval $[0,2]$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3IJUnuTZdS1"
      },
      "source": [
        "N = 100\n",
        "max_epochs = 1000\n",
        "tol = 1e-8\n",
        "\n",
        "np.random.seed(0)\n",
        "x = np.random.rand(N)*2\n",
        "\n",
        "...\n",
        "\n",
        "while ...\n",
        "    epoch += 1\n",
        "    # search direction\n",
        "    p = ...\n",
        "    \n",
        "    # line search\n",
        "    line_search = sp.optimize.line_search(loss_jit, grad_jit, x, p)\n",
        "    alpha = line_search[0]\n",
        "    x_new = x + alpha * p\n",
        "\n",
        "    ..."
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}