{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"handwriting_recognition_ANN.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMFUpmVMW28aAEqdI2WzCsf"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"4ky2ALT8aFZq"},"source":["# Handwriting recognition"]},{"cell_type":"code","metadata":{"id":"3uD05d77CfLv"},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import jax.numpy as jnp\n","import jax\n","import time"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LWxlDFYZx31S"},"source":["## Data import and visualization"]},{"cell_type":"markdown","metadata":{"id":"hRNhX9i6vwuT"},"source":["Import the MNIST train dataset ([https://en.wikipedia.org/wiki/MNIST_database](https://en.wikipedia.org/wiki/MNIST_database))"]},{"cell_type":"code","metadata":{"id":"Tb2dI5WU-2ji"},"source":["# This dataset is contained in the sample data directory of Google Colab online runtimes\n","data = np.genfromtxt('sample_data/mnist_train_small.csv', delimiter=',')\n","data.shape"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TtWMNidPv9y_"},"source":["Store the data in a matrix and the labels in a vector.\n","\n","**REMARK**: in this lab we will work with features/classes on rows and samples on columns."]},{"cell_type":"code","metadata":{"id":"yzGMpNrABkpe"},"source":["labels = data[:,0]\n","x_data = data[:,1:].transpose() / 255\n","labels.shape, x_data.shape"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-9AwDHzcwSx3"},"source":["Visualize the first 30 pictures with the corresponding labels"]},{"cell_type":"code","metadata":{"id":"Nd6cnbmu_Gvv"},"source":["fig, axs = plt.subplots(ncols = 10, nrows = 3, figsize = (20,6))\n","axs = axs.reshape((-1,))\n","for i in range(30):\n","  image_i = x_data[:,i].reshape((28,28))\n","  axs[i].imshow(image_i, cmap='gray')\n","  axs[i].set_title(int(labels[i]))\n","  axs[i].axis('off')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"i8lATi3kOnBs"},"source":["Create a [one-hot](https://en.wikipedia.org/wiki/One-hot) representation of the labels, that is a matrix where each row corresponds to a class (i.e. a digit).\n","the entries of the matrix are 1 if the sample corresponds to that digit, 0 otherwise."]},{"cell_type":"code","metadata":{"id":"fvaLuITMCstt"},"source":["y_data = np.zeros((10, 20000))\n","for i in range(10):\n","  y_data[i, labels==i] = 1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4ZGpB1VwSceh"},"source":["Check that the matrix has exactly one element \"1\" in each column."]},{"cell_type":"code","metadata":{"id":"Exa59aV0SYHq"},"source":["row_sums = np.sum(y_data, axis = 0)\n","row_sums.min(), row_sums.max()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KDkeuzgpTonk"},"source":["## ANN training\n","\n","Write a function to initialize the parameters (with Glorot Normal initialization) and a function implementing a feedforward ANN with tanh activation function.\n","\n","To the last layer of the ANN, apply a *soft-max* layer. If $z_1, \\dots, z_n$ are the activations of the last layer neurons, the soft-max layer produces $\\hat{z}_1, \\dots, \\hat{z}_n$, defined as\n","$$\n","\\hat{z}_i = \\frac{e^{z_i}}{\\sum_{j=1}^n e^{z_j}}\n","$$\n","In this manner the outputs of the ANN satisfy by construction:\n","- $\\hat{z}_i \\in [0,1]$\n","- $\\sum_{j=1}^n \\hat{z}_j = 1$\n","\n","Therefore, they can be intepreted as probabilities.\n","\n","When the ANN will be trained, we will take the digit corresponding the the hightest proabability as prediction of the model."]},{"cell_type":"markdown","metadata":{"id":"qwfvKVggVH0b"},"source":["Test the ANN and check that the above properties are satisfied."]},{"cell_type":"markdown","metadata":{"id":"pMbemXuAU7gh"},"source":["Implement the following metrics:\n","- mean square error\n","- cross entropy\n","- accuracy (fraction of samples correctly classified)"]},{"cell_type":"code","source":["def MSE(x, y, params):\n","  ...\n","\n","def cross_entropy(x, y, params):\n","  ...\n","\n","def accuracy(x, y, params):\n","  ...\n","\n","print('MSE:       %f' % MSE(x_data, y_data, params))\n","print('X entropy: %f' % cross_entropy(x_data, y_data, params))\n","print('accuracy:  %f' % accuracy(x_data, y_data, params))"],"metadata":{"id":"KRVZND2sgiIw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dxPA1pV5X4Ml"},"source":["Put 10000 images in the training set and 1000 images in the validation set."]},{"cell_type":"markdown","metadata":{"id":"F-DzsGukYo2Q"},"source":["Run this cell. We will use it later."]},{"cell_type":"code","metadata":{"id":"NrdFgazmQhVz"},"source":["from IPython import display\n","\n","class Callback:\n","  def __init__(self, refresh_rate = 250):\n","    self.refresh_rate = refresh_rate\n","    self.fig, self.axs = plt.subplots(1, figsize=(16,8))\n","    self.epoch = 0\n","    self.__call__(-1)\n","\n","  def __call__(self, epoch):\n","    self.epoch = epoch\n","    if (epoch + 1) % self.refresh_rate == 0:\n","      self.draw()\n","      display.clear_output(wait=True)\n","      display.display(plt.gcf())\n","      time.sleep(1e-16)\n","\n","  def draw(self):\n","    if self.epoch > 0:\n","      self.axs.clear()\n","      epochs = np.arange(1,len(history_train_Xen) + 1)\n","      self.axs.loglog(epochs, history_train_Xen, label = 'train_Xen')\n","      self.axs.loglog(epochs, history_valid_Xen, label = 'valid_Xen')\n","      self.axs.loglog(epochs, history_valid_MSE, label = 'valid_MSE')\n","      self.axs.loglog(epochs, history_valid_acc, label = 'valid_acc')\n","\n","      self.axs.legend()\n","      self.axs.set_title('epoch %d - accuracy %0.1f%%' % (self.epoch + 1, 100*history_valid_acc[-1]))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3TH0_K-AaO7k"},"source":["Train an ANN-based classifier with two hidden layers with 50 neurons each.\n","Use 500 epochs of the RMSProp algorithm, with decay rate 0.9 and $\\delta = 10^{-7}$ and fixed learning rate $\\lambda = 0.002$. Use minibatches with batch size of 1000.\n","\n","Use the cross-entropy loss to drive the training.\n","To monitor training, store every 10 training epochs the following metrics in the following lists:\n","- `history_train_Xen`: cross-entropy (training set)\n","- `history_valid_Xen`: cross-entropy (validation set)\n","- `history_valid_MSE`: MSE (validation set)\n","- `history_valid_acc`: accuracy (validation set)"]},{"cell_type":"code","source":["# Hyperparameters\n","layers_size = [784, 50, 50, 10]\n","# Training options\n","num_epochs = 500\n","batch_size = 1000\n","learning_rate = 2e-3\n","decay_rate = .9\n","delta = 1e-7\n","\n","history_train_Xen = list()\n","history_valid_Xen = list()\n","history_valid_MSE = list()\n","history_valid_acc = list()"],"metadata":{"id":"dd62k-BxjkYR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mYN_CQrCs7TR"},"source":["## Testing"]},{"cell_type":"markdown","metadata":{"id":"CLLoZBE70wmM"},"source":["Load the dataset `sample_data/mnist_test.csv` and compute the accuracy of the classifier on this dataset."]},{"cell_type":"code","metadata":{"id":"P-KXleHts6xy"},"source":["data_test = np.genfromtxt('sample_data/mnist_test.csv', delimiter=',')\n","data_test.shape\n","labels_test = data_test[:,0]\n","x_test = data_test[:,1:].transpose() / 255\n","y_test = np.zeros((10, x_test.shape[1]))\n","for i in range(10):\n","  y_test[i, labels_test==i] = 1\n","x_test.shape, y_test.shape"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tJSRUqyE08r4"},"source":["Use the following script to visualize the predictions on a bunch of test images."]},{"cell_type":"code","metadata":{"id":"2AIAKPAStXfz"},"source":["offset = 0\n","n_images = 40\n","\n","images_per_row = 10\n","y_predicted = ANN(x_test[:,offset:offset+n_images], params)\n","\n","def draw_bars(ax, y_predicted, label):\n","    myplot = ax.bar(range(10), (y_predicted))\n","    ax.set_ylim([0,1])\n","    ax.set_xticks(range(10))\n","\n","    label_predicted = np.argmax(y_predicted)\n","    if label == label_predicted:\n","      color = 'green'\n","    else:\n","      color = 'red'\n","    myplot[label_predicted].set_color(color)\n","\n","import math\n","n_rows = 2 * math.ceil(n_images / images_per_row)\n","_, axs = plt.subplots(n_rows, images_per_row, figsize = (3*images_per_row, 3*n_rows))\n","row = 0\n","col = 0\n","for i in range(n_images):\n","  axs[2*row,col].imshow(x_test[:,offset+i].reshape((28,28)), cmap='gray')\n","  axs[2*row,col].set_title(int(labels_test[offset+i]))\n","  axs[2*row,col].axis('off')\n","\n","  draw_bars(axs[2*row+1,col], y_predicted[:,i], labels_test[offset+i])\n","\n","  col += 1\n","  if col == images_per_row:\n","    col = 0\n","    row += 1\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Xs9nPbRiJpeP"},"source":["# Adversarial attacks\n","\n","You have trained your classifier. Cool, isn't it? Let us now try to fool it.\n","\n","Consider the last image of the training set. Visualize it and visualize the associated predictions of the classifier."]},{"cell_type":"code","metadata":{"id":"pSec_8lB9nW9"},"source":["x = x_data[:,-1][:,None]\n","y = y_data[:,-1][:,None]\n","label = np.argmax(y)\n","\n","_, axs = plt.subplots(1,2, figsize = (8,4))\n","axs[0].imshow(x.reshape((28,28)), cmap = 'gray')\n","axs[0].axis('off')\n","\n","y_pred = ANN(x, params)\n","\n","draw_bars(axs[1], y_pred[:,0], label)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"V1yZaDFFKKBk"},"source":["An adversarial attack consists of an (almost imperceptible) modification of the image, aimed at fooling the classifier into making a mistake.\n","See e.g. [this article](https://www.wired.com/story/tesla-speed-up-adversarial-example-mgm-breach-ransomware/)\n","\n","To hack the classifier, compute the gradient of cross entropy loss funcion with respect to the input (not to the parameters!). Then, superimpose a multiple of the gradient to the original image.\n","\n","Visualize the original and the hacked images and the corresponding prediction of the classifier."]},{"cell_type":"code","source":["gradient = ...\n","x_updated = ...\n","y_updated = ...\n","\n","_, axs = plt.subplots(1,5,figsize=(20,4))\n","axs[0].imshow(x.reshape((28,28)), cmap = 'gray')\n","axs[0].set_title('original picture')\n","draw_bars(axs[1], y_pred[:,0], label)\n","axs[2].imshow(gradient.reshape((28,28)), cmap = 'gray')\n","axs[2].set_title('gradient')\n","axs[3].imshow(x_updated.reshape((28,28)), cmap = 'gray')\n","axs[3].set_title('hacked picture')\n","draw_bars(axs[4], y_updated[:,0], label)"],"metadata":{"id":"FkZrCVm2W_bu"},"execution_count":null,"outputs":[]}]}