{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"intro_to_TensorFlow.ipynb","provenance":[],"authorship_tag":"ABX9TyOEyQ80sYFN0Q23g3w/MCJD"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"gykGREfvOyne"},"source":["# An introduction to TensorFlow\n","\n","<div align=\"center\">\n","  <img src=\"https://www.tensorflow.org/images/tf_logo_social.png\">\n","</div>\n","\n","[TensorFlow](https://www.tensorflow.org/) is a free and open-source software library for machine learning. It can be used across a range of tasks but has a particular focus on training and inference of deep neural networks.\n","TensorFlow was developed by the [Google Brain](https://en.wikipedia.org/wiki/Google_Brain) team for internal Google use. It is used for both research and production at Google.\n","\n","TensorFlow was first released in 2015.\n","\n","In September 2019, TensorFlow 2.0 was released, with significant changes with respect to TensorFlow 1.0 (codes are not backward compatible!).\n","\n","The current stable version in 2.6.0 (November 2021).\n","\n","- [Tutorial](https://www.tensorflow.org/tutorials)\n","- [Guide](https://www.tensorflow.org/guide)\n","- [Python API reference](https://www.tensorflow.org/api_docs/python/tf)\n","- [GitHub development repository](https://github.com/tensorflow/tensorflow)"]},{"cell_type":"code","metadata":{"id":"nll5C_uEUarJ"},"source":["import tensorflow as tf\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hvwZJWQsSmiL"},"source":["## Tensors"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kV3Hoc0tSp1W","executionInfo":{"status":"ok","timestamp":1639146427748,"user_tz":-60,"elapsed":218,"user":{"displayName":"Francesco Regazzoni","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08593163129562527691"}},"outputId":"08dd0c94-22dc-459e-eae2-85311d822d90"},"source":["rank_0_tensor = tf.constant(4)\n","print(rank_0_tensor)\n","\n","rank_1_tensor = tf.constant([2.0, 3.0, 4.0])\n","print(rank_1_tensor)\n","\n","rank_2_tensor = tf.constant([[1, 2],\n","                             [3, 4],\n","                             [5, 6]], dtype=tf.float16)\n","print(rank_2_tensor)"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor(4, shape=(), dtype=int32)\n","tf.Tensor([2. 3. 4.], shape=(3,), dtype=float32)\n","tf.Tensor(\n","[[1. 2.]\n"," [3. 4.]\n"," [5. 6.]], shape=(3, 2), dtype=float16)\n"]}]},{"cell_type":"markdown","metadata":{"id":"CFpPpONLS4HD"},"source":["<table>\n","<tr>\n","  <th>A scalar, shape: <code>[]</code></th>\n","  <th>A vector, shape: <code>[3]</code></th>\n","  <th>A matrix, shape: <code>[3, 2]</code></th>\n","</tr>\n","<tr>\n","  <td>\n","   <img src=\"https://github.com/tensorflow/docs/blob/master/site/en/guide/images/tensor/scalar.png?raw=1\"/>\n","  </td>\n","\n","  <td>\n","   <img src=\"https://github.com/tensorflow/docs/blob/master/site/en/guide/images/tensor/vector.png?raw=1\"/>\n","  </td>\n","  <td>\n","   <img src=\"https://github.com/tensorflow/docs/blob/master/site/en/guide/images/tensor/matrix.png?raw=1\">\n","  </td>\n","</tr>\n","</table>"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-OjpxjxJTyXz","executionInfo":{"status":"ok","timestamp":1639146438514,"user_tz":-60,"elapsed":190,"user":{"displayName":"Francesco Regazzoni","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08593163129562527691"}},"outputId":"388cd4db-2c6b-4915-eaf1-d6d154a011fe"},"source":["# There can be an arbitrary number of\n","# axes (sometimes called \"dimensions\")\n","rank_3_tensor = tf.constant([\n","  [[0, 1, 2, 3, 4],\n","   [5, 6, 7, 8, 9]],\n","  [[10, 11, 12, 13, 14],\n","   [15, 16, 17, 18, 19]],\n","  [[20, 21, 22, 23, 24],\n","   [25, 26, 27, 28, 29]],])\n","\n","print(rank_3_tensor)"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor(\n","[[[ 0  1  2  3  4]\n","  [ 5  6  7  8  9]]\n","\n"," [[10 11 12 13 14]\n","  [15 16 17 18 19]]\n","\n"," [[20 21 22 23 24]\n","  [25 26 27 28 29]]], shape=(3, 2, 5), dtype=int32)\n"]}]},{"cell_type":"markdown","metadata":{"id":"yNFVEfwcTPui"},"source":["<table>\n","<tr>\n","  <th colspan=3>A 3-axis tensor, shape: <code>[3, 2, 5]</code></th>\n","<tr>\n","<tr>\n","  <td>\n","   <img src=\"https://github.com/tensorflow/docs/blob/master/site/en/guide/images/tensor/3-axis_numpy.png?raw=1\"/>\n","  </td>\n","  <td>\n","   <img src=\"https://github.com/tensorflow/docs/blob/master/site/en/guide/images/tensor/3-axis_front.png?raw=1\"/>\n","  </td>\n","\n","  <td>\n","   <img src=\"https://github.com/tensorflow/docs/blob/master/site/en/guide/images/tensor/3-axis_block.png?raw=1\"/>\n","  </td>\n","</tr>\n","\n","</table>"]},{"cell_type":"markdown","metadata":{"id":"Bwlm3rTTUFyV"},"source":["You can convert a tensor to a NumPy array either using `np.array` or the `tensor.numpy` method:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1OVcJu1NUFIX","executionInfo":{"status":"ok","timestamp":1639146447401,"user_tz":-60,"elapsed":200,"user":{"displayName":"Francesco Regazzoni","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08593163129562527691"}},"outputId":"1718c673-6d00-4fe9-9395-e610a5160d19"},"source":["np.array(rank_2_tensor)"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[1., 2.],\n","       [3., 4.],\n","       [5., 6.]], dtype=float16)"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"thFM5jBZUIdL","executionInfo":{"status":"ok","timestamp":1639146453312,"user_tz":-60,"elapsed":221,"user":{"displayName":"Francesco Regazzoni","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08593163129562527691"}},"outputId":"b0ce1b7d-2a21-4153-93ce-a31147c7594d"},"source":["rank_2_tensor.numpy()"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[1., 2.],\n","       [3., 4.],\n","       [5., 6.]], dtype=float16)"]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"wZtY6J4_UQLn"},"source":["Tensors often contain floats and ints, but have many other types, including:\n","\n","* complex numbers\n","* strings\n","\n","The base `tf.Tensor` class requires tensors to be \"rectangular\"---that is, along each axis, every element is the same size.  However, there are specialized types of tensors that can handle different shapes:\n","\n","* Ragged tensors\n","* Sparse tensors\n","\n","You can do basic math on tensors, including addition, element-wise multiplication, and matrix multiplication."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4cAD-i-1UW5W","executionInfo":{"status":"ok","timestamp":1639146498242,"user_tz":-60,"elapsed":185,"user":{"displayName":"Francesco Regazzoni","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08593163129562527691"}},"outputId":"51305b50-e9eb-4993-a1d2-bc3642e52ca1"},"source":["a = tf.constant([[1, 2],\n","                 [3, 4]])\n","b = tf.constant([[1, 1],\n","                 [1, 1]]) # Could have also said `tf.ones([2,2])`\n","\n","print(tf.add(a, b), \"\\n\")\n","print(tf.multiply(a, b), \"\\n\")\n","print(tf.matmul(a, b), \"\\n\")"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor(\n","[[2 3]\n"," [4 5]], shape=(2, 2), dtype=int32) \n","\n","tf.Tensor(\n","[[1 2]\n"," [3 4]], shape=(2, 2), dtype=int32) \n","\n","tf.Tensor(\n","[[3 3]\n"," [7 7]], shape=(2, 2), dtype=int32) \n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DaLEvdaFUYbG","executionInfo":{"status":"ok","timestamp":1639146527152,"user_tz":-60,"elapsed":209,"user":{"displayName":"Francesco Regazzoni","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08593163129562527691"}},"outputId":"8813b3b7-4358-495c-98ad-98397727f30d"},"source":["print(a + b, \"\\n\") # element-wise addition\n","print(a * b, \"\\n\") # element-wise multiplication\n","print(a @ b, \"\\n\") # matrix multiplication"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor(\n","[[2 3]\n"," [4 5]], shape=(2, 2), dtype=int32) \n","\n","tf.Tensor(\n","[[1 2]\n"," [3 4]], shape=(2, 2), dtype=int32) \n","\n","tf.Tensor(\n","[[3 3]\n"," [7 7]], shape=(2, 2), dtype=int32) \n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uAkK0BlPUnRg","executionInfo":{"status":"ok","timestamp":1639146573423,"user_tz":-60,"elapsed":185,"user":{"displayName":"Francesco Regazzoni","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08593163129562527691"}},"outputId":"21288252-ba38-472e-81c7-1890cd6baee0"},"source":["c = tf.constant([[4.0, 5.0], [10.0, 1.0]])\n","\n","# Find the largest value\n","print(tf.reduce_max(c), \"\\n\")\n","# Find the index of the largest value\n","print(tf.argmax(c), \"\\n\")\n","# Compute the softmax\n","print(tf.nn.softmax(c), \"\\n\")"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor(10.0, shape=(), dtype=float32) \n","\n","tf.Tensor([1 0], shape=(2,), dtype=int64) \n","\n","tf.Tensor(\n","[[2.6894143e-01 7.3105860e-01]\n"," [9.9987662e-01 1.2339458e-04]], shape=(2, 2), dtype=float32) \n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"PNi9sorrUwY1"},"source":["### About shapes\n","\n","Tensors have shapes.  Some vocabulary:\n","\n","* **Shape**: The length (number of elements) of each of the dimensions of a tensor.\n","* **Rank**: Number of tensor dimensions.  A scalar has rank 0, a vector has rank 1, a matrix is rank 2.\n","* **Axis** or **Dimension**: A particular dimension of a tensor.\n","* **Size**: The total number of items in the tensor, the product shape vector\n","\n","Tensors and `tf.TensorShape` objects have convenient properties for accessing these:"]},{"cell_type":"code","metadata":{"id":"wmYXnjbIU6sS","executionInfo":{"status":"ok","timestamp":1639146616037,"user_tz":-60,"elapsed":175,"user":{"displayName":"Francesco Regazzoni","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08593163129562527691"}}},"source":["rank_4_tensor = tf.zeros([3, 2, 4, 5])"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wTXiTvneU87E"},"source":["<table>\n","<tr>\n","  <th colspan=2>A rank-4 tensor, shape: <code>[3, 2, 4, 5]</code></th>\n","</tr>\n","<tr>\n","  <td>\n","<img src=\"https://github.com/tensorflow/docs/blob/master/site/en/guide/images/tensor/shape.png?raw=1\" alt=\"A tensor shape is like a vector.\">\n","    <td>\n","<img src=\"https://github.com/tensorflow/docs/blob/master/site/en/guide/images/tensor/4-axis_block.png?raw=1\" alt=\"A 4-axis tensor\">\n","  </td>\n","  </tr>\n","</table>"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zu2aSFrdVHw8","executionInfo":{"status":"ok","timestamp":1639146625843,"user_tz":-60,"elapsed":179,"user":{"displayName":"Francesco Regazzoni","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08593163129562527691"}},"outputId":"634f6a6e-0a12-4630-8046-0f3293b57276"},"source":["print(\"Type of every element:\", rank_4_tensor.dtype)\n","print(\"Number of dimensions:\", rank_4_tensor.ndim)\n","print(\"Shape of tensor:\", rank_4_tensor.shape)\n","print(\"Elements along axis 0 of tensor:\", rank_4_tensor.shape[0])\n","print(\"Elements along the last axis of tensor:\", rank_4_tensor.shape[-1])\n","print(\"Total number of elements (3*2*4*5): \", tf.size(rank_4_tensor).numpy())"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Type of every element: <dtype: 'float32'>\n","Number of dimensions: 4\n","Shape of tensor: (3, 2, 4, 5)\n","Elements along axis 0 of tensor: 3\n","Elements along the last axis of tensor: 5\n","Total number of elements (3*2*4*5):  120\n"]}]},{"cell_type":"markdown","metadata":{"id":"8DM8aQbaVQuh"},"source":["### Indexing\n","\n","TensorFlow follows standard Python indexing rules, similar to [indexing a list or a string in Python](https://docs.python.org/3/tutorial/introduction.html#strings), and the basic rules for NumPy indexing."]},{"cell_type":"code","metadata":{"id":"dvFkmvXpVT4U","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1639146637039,"user_tz":-60,"elapsed":176,"user":{"displayName":"Francesco Regazzoni","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08593163129562527691"}},"outputId":"ba844fec-1b9d-45fe-de0b-9d23e8898486"},"source":["rank_1_tensor = tf.constant([0, 1, 1, 2, 3, 5, 8, 13, 21, 34])\n","print(rank_1_tensor.numpy())"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["[ 0  1  1  2  3  5  8 13 21 34]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kH_YCWaOVVE9","executionInfo":{"status":"ok","timestamp":1639146653686,"user_tz":-60,"elapsed":182,"user":{"displayName":"Francesco Regazzoni","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08593163129562527691"}},"outputId":"d8a8ba31-ce9d-43fe-fc95-6a2b32d85145"},"source":["print(\"First:\", rank_1_tensor[0].numpy())\n","print(\"Second:\", rank_1_tensor[1].numpy())\n","print(\"Last:\", rank_1_tensor[-1].numpy())\n","print(\"Everything:\", rank_1_tensor[:].numpy())\n","print(\"Before 4:\", rank_1_tensor[:4].numpy())\n","print(\"From 4 to the end:\", rank_1_tensor[4:].numpy())\n","print(\"From 2, before 7:\", rank_1_tensor[2:7].numpy())\n","print(\"Every other item:\", rank_1_tensor[::2].numpy())\n","print(\"Reversed:\", rank_1_tensor[::-1].numpy())"],"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["First: 0\n","Second: 1\n","Last: 34\n","Everything: [ 0  1  1  2  3  5  8 13 21 34]\n","Before 4: [0 1 1 2]\n","From 4 to the end: [ 3  5  8 13 21 34]\n","From 2, before 7: [1 2 3 5 8]\n","Every other item: [ 0  1  3  8 21]\n","Reversed: [34 21 13  8  5  3  2  1  1  0]\n"]}]},{"cell_type":"markdown","metadata":{"id":"HmTsdqcRVed-"},"source":["Moreover, operations such as multi-indexing, reshaping, permutation are available in a similar fashion to NumPy."]},{"cell_type":"markdown","metadata":{"id":"e0cfocc9V29e"},"source":["## Automatic Differentiation"]},{"cell_type":"markdown","metadata":{"id":"4GXAePP8WCF6"},"source":["To differentiate automatically, TensorFlow needs to remember what operations happen in what order during the *forward* pass.  Then, during the *backward pass*, TensorFlow traverses this list of operations in reverse order to compute gradients."]},{"cell_type":"markdown","metadata":{"id":"ylvcIhixWJG0"},"source":["## Gradient tapes\n","\n","TensorFlow provides the [tf.GradientTape](https://www.tensorflow.org/api_docs/python/tf/GradientTape) API for automatic differentiation; that is, computing the gradient of a computation with respect to some inputs, usually `tf.Variable`s.\n","TensorFlow \"records\" relevant operations executed inside the context of a `tf.GradientTape` onto a \"tape\". TensorFlow then uses that tape to compute the gradients of a \"recorded\" computation using [reverse mode differentiation](https://en.wikipedia.org/wiki/Automatic_differentiation).\n","\n","Here is a simple example:"]},{"cell_type":"code","metadata":{"id":"aFCLSQZ1WLLz","executionInfo":{"status":"ok","timestamp":1639146817080,"user_tz":-60,"elapsed":218,"user":{"displayName":"Francesco Regazzoni","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08593163129562527691"}}},"source":["x = tf.Variable(3.0)\n","\n","with tf.GradientTape() as tape:\n","  y = x**2"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WnxLGMqTWPRZ"},"source":["Once you've recorded some operations, use `GradientTape.gradient(target, sources)` to calculate the gradient of some target (often a loss) relative to some source (often the model's variables)."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zd2EUCGUWSAC","executionInfo":{"status":"ok","timestamp":1639146846948,"user_tz":-60,"elapsed":189,"user":{"displayName":"Francesco Regazzoni","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08593163129562527691"}},"outputId":"4faddba4-b7f7-40b4-9cc3-e3f76609f323"},"source":["# dy = 2x * dx\n","dy_dx = tape.gradient(y, x)\n","dy_dx.numpy()"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["6.0"]},"metadata":{},"execution_count":15}]},{"cell_type":"markdown","metadata":{"id":"70bNHotaWUNi"},"source":["The above example uses scalars, but `tf.GradientTape` works as easily on any tensor:"]},{"cell_type":"code","metadata":{"id":"527Bd9EHWWrW","executionInfo":{"status":"ok","timestamp":1639146926448,"user_tz":-60,"elapsed":212,"user":{"displayName":"Francesco Regazzoni","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08593163129562527691"}}},"source":["w = tf.Variable(tf.random.normal((3, 2)), name='w')\n","b = tf.Variable(tf.zeros(2, dtype=tf.float32), name='b')\n","x = [[1., 2., 3.]]\n","\n","def ANN(x,w,b):\n","  return x @ w - b\n","\n","def loss_func(y):\n","  return tf.reduce_mean(y**2)\n","\n","with tf.GradientTape() as tape:\n","  y = ANN(x,w,b)\n","  loss = loss_func(y)"],"execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Fdaf10lPWaTl"},"source":["To get the gradient of `y` with respect to both variables, you can pass both as sources to the `gradient` method. The tape is flexible about how sources are passed and will accept any nested combination of lists or dictionaries and return the gradient structured the same way (see `tf.nest`)."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AAIQijO6WcF3","executionInfo":{"status":"ok","timestamp":1639146945764,"user_tz":-60,"elapsed":187,"user":{"displayName":"Francesco Regazzoni","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08593163129562527691"}},"outputId":"4d9258bc-30c6-4013-9b47-0ab49f0ce393"},"source":["[dl_dw, dl_db] = tape.gradient(loss, [w, b])\n","print(dl_dw, \"\\n\")\n","print(dl_db, \"\\n\")"],"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor(\n","[[-0.6865128  5.561805 ]\n"," [-1.3730257 11.12361  ]\n"," [-2.0595384 16.685413 ]], shape=(3, 2), dtype=float32) \n","\n","tf.Tensor([ 0.6865128 -5.561805 ], shape=(2,), dtype=float32) \n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"pLKD47UJZOT8"},"source":["### Controlling what the tape watches\n","\n","The default behavior is to record all operations after accessing a trainable `tf.Variable`. The reasons for this are:\n","\n","* The tape needs to know which operations to record in the forward pass to calculate the gradients in the backwards pass.\n","* The tape holds references to intermediate outputs, so you don't want to record unnecessary operations.\n","* The most common use case involves calculating the gradient of a loss with respect to all a model's trainable variables.\n","\n","For example the following fails to calculate a gradient because the `tf.Tensor` is not \"watched\" by default, and the `tf.Variable` is not trainable:\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4tUodrqiZXOs","executionInfo":{"status":"ok","timestamp":1639147109682,"user_tz":-60,"elapsed":214,"user":{"displayName":"Francesco Regazzoni","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08593163129562527691"}},"outputId":"0d2ca6c2-6210-4bbc-f773-fe0b41734028"},"source":["# A trainable variable\n","x0 = tf.Variable(3.0, name='x0')\n","# Not trainable\n","x1 = tf.Variable(3.0, name='x1', trainable=False)\n","# Not a Variable: A variable + tensor returns a tensor.\n","x2 = tf.Variable(2.0, name='x2') + 1.0\n","# Not a variable\n","x3 = tf.constant(3.0, name='x3')\n","\n","with tf.GradientTape() as tape:\n","  y = (x0**2) + (x1**2) + (x2**2) + (x3**2)\n","\n","grad = tape.gradient(y, [x0, x1, x2, x3])\n","\n","for g in grad:\n","  print(g)"],"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor(6.0, shape=(), dtype=float32)\n","None\n","None\n","None\n"]}]},{"cell_type":"markdown","metadata":{"id":"dafoXp5vZdPD"},"source":["You can list the variables being watched by the tape using the `GradientTape.watched_variables` method:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EeJN6rtiZbuw","executionInfo":{"status":"ok","timestamp":1639147131230,"user_tz":-60,"elapsed":192,"user":{"displayName":"Francesco Regazzoni","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08593163129562527691"}},"outputId":"46973a51-9109-4957-e85a-27200a22fe60"},"source":["[var.name for var in tape.watched_variables()]"],"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['x0:0']"]},"metadata":{},"execution_count":19}]},{"cell_type":"markdown","metadata":{"id":"ga-R8W3HZgG9"},"source":["`tf.GradientTape` provides hooks that give the user control over what is or is not watched.\n","\n","To record gradients with respect to a `tf.Tensor`, you need to call `GradientTape.watch(x)`:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FNa7P2v9Zhib","executionInfo":{"status":"ok","timestamp":1639147157832,"user_tz":-60,"elapsed":181,"user":{"displayName":"Francesco Regazzoni","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08593163129562527691"}},"outputId":"5043914d-a6e8-4468-8247-c3d600cb944b"},"source":["x = tf.constant(3.0)\n","with tf.GradientTape() as tape:\n","  tape.watch(x)\n","  y = x**2\n","\n","# dy = 2x * dx\n","dy_dx = tape.gradient(y, x)\n","print(dy_dx.numpy())"],"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["6.0\n"]}]},{"cell_type":"markdown","metadata":{"id":"0JieOegtZqoa"},"source":["Conversely, to disable the default behavior of watching all `tf.Variables`, set `watch_accessed_variables=False` when creating the gradient tape. This calculation uses two variables, but only connects the gradient for one of the variables:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t_xoralpZr-E","executionInfo":{"status":"ok","timestamp":1639147187856,"user_tz":-60,"elapsed":180,"user":{"displayName":"Francesco Regazzoni","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08593163129562527691"}},"outputId":"052e70a8-5969-4f30-efbb-4316fcbbfe6c"},"source":["x0 = tf.Variable(0.0)\n","x1 = tf.Variable(10.0)\n","\n","with tf.GradientTape(watch_accessed_variables=False) as tape:\n","  tape.watch(x1)\n","  y0 = tf.math.sin(x0)\n","  y1 = tf.nn.softplus(x1)\n","  y = y0 + y1\n","  ys = tf.reduce_sum(y)\n","\n","# dy = 2x * dx\n","grad = tape.gradient(ys, {'x0': x0, 'x1': x1})\n","\n","print('dy/dx0:', grad['x0'])\n","print('dy/dx1:', grad['x1'].numpy())"],"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["dy/dx0: None\n","dy/dx1: 0.9999546\n"]}]},{"cell_type":"markdown","metadata":{"id":"UCcmQ7W4ZvxC"},"source":["Since `GradientTape.watch` was not called on `x0`, no gradient is computed with respect to it."]},{"cell_type":"markdown","metadata":{"id":"HZadWByiW-xT"},"source":["### Intermediate results\n","\n","You can also request gradients of the output with respect to intermediate values computed inside the `tf.GradientTape` context."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fK1HTNIHXAL7","executionInfo":{"status":"ok","timestamp":1639147245528,"user_tz":-60,"elapsed":188,"user":{"displayName":"Francesco Regazzoni","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08593163129562527691"}},"outputId":"a8b5410f-3ff3-49a8-bc3c-2b06b0718ef6"},"source":["x = tf.constant(3.0)\n","\n","with tf.GradientTape() as tape:\n","  tape.watch(x)\n","  y = x * x\n","  z = y * y\n","\n","# Use the tape to compute the gradient of z with respect to the intermediate value y.\n","# dz_dx = 2 * y, where y = x ** 2\n","print(tape.gradient(z, y).numpy())"],"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["18.0\n"]}]},{"cell_type":"markdown","metadata":{"id":"sFPtRWQjXEPy"},"source":["By default, the resources held by a `GradientTape` are released as soon as `GradientTape.gradient()` method is called. To compute multiple gradients over the same computation, create a `persistent` gradient tape. This allows multiple calls to the `gradient()` method as resources are released when the tape object is garbage collected. For example:"]},{"cell_type":"code","metadata":{"id":"zzVudxXKXIOz"},"source":["x = tf.constant([1, 3.0])\n","with tf.GradientTape(persistent=True) as tape:\n","  tape.watch(x)\n","  y = x * x\n","  z = y * y\n","\n","print(tape.gradient(z, x).numpy())  # 108.0 (4 * x**3 at x = 3)\n","print(tape.gradient(y, x).numpy())  # 6.0 (2 * x)"],"execution_count":null,"outputs":[]}]}