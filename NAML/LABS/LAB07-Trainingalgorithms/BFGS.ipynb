{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "qdCkH2JM07eu"
      },
      "source": [
        "# Quasi-Newton methods: BFGS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "T9vAduWLjiTl"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import scipy.optimize\n",
        "import scipy as sp\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# We enable double precision in JAX\n",
        "from jax.config import config\n",
        "\n",
        "config.update(\"jax_enable_x64\", True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "VQmGG5duO6ig"
      },
      "source": [
        "Consider the [Rosenbrock function](https://en.wikipedia.org/wiki/Rosenbrock_function), that is minimized in $\\mathbf{x} = (1,1,\\dots,1)^T$:\n",
        "\n",
        "$$\\mathcal{L}(\\mathbf{x}) = \\sum_{i=1}^{N-1} [100 (x_{i+1} - x_i^2 )^2 + (1-x_i)^2]$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Ybmumhr1z32F"
      },
      "outputs": [],
      "source": [
        "def loss(x):\n",
        "    return sum(100.0 * (x[1:] - x[:-1] ** 2) ** 2 + (1 - x[:-1]) ** 2)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "opnXVnczPDLj"
      },
      "source": [
        "Use `jax` to compute and compile the Rosenbrock function and its gradient."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "grad = jax.grad(loss)\n",
        "\n",
        "loss_jit = jax.jit(loss)\n",
        "grad_jit = jax.jit(grad)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "CEvFRykGQtzx"
      },
      "source": [
        "Implement the BFGS method (with line search) for the minimization of the Rosenbrock function.\n",
        "Set a maximum of 1000 epochs and a stopping tolerance on the gradient eucledian norm of $10^{-8}$. Employ an initial guess for $\\mathbf{x}$ with random numbers in the interval $[0,2]$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "t3IJUnuTZdS1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- epoch 1\n",
            "loss: 7.382e+03\n",
            "gradient 2 norm: 4.952e+03\n",
            "--- epoch 2\n",
            "loss: 4.066e+03\n",
            "gradient 2 norm: 2.503e+03\n",
            "--- epoch 3\n",
            "loss: 3.017e+03\n",
            "gradient 2 norm: 1.933e+03\n",
            "--- epoch 4\n",
            "loss: 2.479e+03\n",
            "gradient 2 norm: 1.510e+03\n",
            "--- epoch 5\n",
            "loss: 2.295e+03\n",
            "gradient 2 norm: 1.419e+03\n",
            "--- epoch 6\n",
            "loss: 2.179e+03\n",
            "gradient 2 norm: 1.342e+03\n",
            "--- epoch 7\n",
            "loss: 2.116e+03\n",
            "gradient 2 norm: 1.290e+03\n",
            "--- epoch 8\n",
            "loss: 2.070e+03\n",
            "gradient 2 norm: 1.267e+03\n",
            "--- epoch 9\n",
            "loss: 2.035e+03\n",
            "gradient 2 norm: 1.248e+03\n",
            "--- epoch 10\n",
            "loss: 2.019e+03\n",
            "gradient 2 norm: 1.268e+03\n",
            "--- epoch 11\n",
            "loss: 1.984e+03\n",
            "gradient 2 norm: 1.250e+03\n",
            "--- epoch 12\n",
            "loss: 1.951e+03\n",
            "gradient 2 norm: 1.238e+03\n",
            "--- epoch 13\n",
            "loss: 1.911e+03\n",
            "gradient 2 norm: 1.211e+03\n",
            "--- epoch 14\n",
            "loss: 1.810e+03\n",
            "gradient 2 norm: 1.163e+03\n",
            "--- epoch 15\n",
            "loss: 1.675e+03\n",
            "gradient 2 norm: 1.163e+03\n",
            "--- epoch 16\n",
            "loss: 1.309e+03\n",
            "gradient 2 norm: 9.353e+02\n",
            "--- epoch 17\n",
            "loss: 1.073e+03\n",
            "gradient 2 norm: 9.330e+02\n",
            "--- epoch 18\n",
            "loss: 9.802e+02\n",
            "gradient 2 norm: 7.764e+02\n",
            "--- epoch 19\n",
            "loss: 8.438e+02\n",
            "gradient 2 norm: 5.606e+02\n",
            "--- epoch 20\n",
            "loss: 7.772e+02\n",
            "gradient 2 norm: 4.656e+02\n",
            "--- epoch 21\n",
            "loss: 7.570e+02\n",
            "gradient 2 norm: 4.578e+02\n",
            "--- epoch 22\n",
            "loss: 7.412e+02\n",
            "gradient 2 norm: 4.325e+02\n",
            "--- epoch 23\n",
            "loss: 7.309e+02\n",
            "gradient 2 norm: 4.068e+02\n",
            "--- epoch 24\n",
            "loss: 7.210e+02\n",
            "gradient 2 norm: 4.029e+02\n",
            "--- epoch 25\n",
            "loss: 7.136e+02\n",
            "gradient 2 norm: 4.103e+02\n",
            "--- epoch 26\n",
            "loss: 7.032e+02\n",
            "gradient 2 norm: 4.029e+02\n",
            "--- epoch 27\n",
            "loss: 6.883e+02\n",
            "gradient 2 norm: 3.974e+02\n",
            "--- epoch 28\n",
            "loss: 6.768e+02\n",
            "gradient 2 norm: 3.896e+02\n",
            "--- epoch 29\n",
            "loss: 6.707e+02\n",
            "gradient 2 norm: 3.931e+02\n",
            "--- epoch 30\n",
            "loss: 6.646e+02\n",
            "gradient 2 norm: 3.824e+02\n",
            "--- epoch 31\n",
            "loss: 6.589e+02\n",
            "gradient 2 norm: 3.845e+02\n",
            "--- epoch 32\n",
            "loss: 6.470e+02\n",
            "gradient 2 norm: 3.842e+02\n",
            "--- epoch 33\n",
            "loss: 6.305e+02\n",
            "gradient 2 norm: 3.813e+02\n",
            "--- epoch 34\n",
            "loss: 6.079e+02\n",
            "gradient 2 norm: 3.973e+02\n",
            "--- epoch 35\n",
            "loss: 5.804e+02\n",
            "gradient 2 norm: 3.606e+02\n",
            "--- epoch 36\n",
            "loss: 5.556e+02\n",
            "gradient 2 norm: 3.653e+02\n",
            "--- epoch 37\n",
            "loss: 5.112e+02\n",
            "gradient 2 norm: 3.094e+02\n",
            "--- epoch 38\n",
            "loss: 4.435e+02\n",
            "gradient 2 norm: 3.062e+02\n",
            "--- epoch 39\n",
            "loss: 4.177e+02\n",
            "gradient 2 norm: 2.918e+02\n",
            "--- epoch 40\n",
            "loss: 4.102e+02\n",
            "gradient 2 norm: 2.889e+02\n",
            "--- epoch 41\n",
            "loss: 4.054e+02\n",
            "gradient 2 norm: 2.822e+02\n",
            "--- epoch 42\n",
            "loss: 4.027e+02\n",
            "gradient 2 norm: 2.841e+02\n",
            "--- epoch 43\n",
            "loss: 4.006e+02\n",
            "gradient 2 norm: 2.791e+02\n",
            "--- epoch 44\n",
            "loss: 3.980e+02\n",
            "gradient 2 norm: 2.753e+02\n",
            "--- epoch 45\n",
            "loss: 3.938e+02\n",
            "gradient 2 norm: 2.744e+02\n",
            "--- epoch 46\n",
            "loss: 3.822e+02\n",
            "gradient 2 norm: 2.643e+02\n",
            "--- epoch 47\n",
            "loss: 3.476e+02\n",
            "gradient 2 norm: 2.385e+02\n",
            "--- epoch 48\n",
            "loss: 3.103e+02\n",
            "gradient 2 norm: 2.231e+02\n",
            "--- epoch 49\n",
            "loss: 2.800e+02\n",
            "gradient 2 norm: 2.159e+02\n",
            "--- epoch 50\n",
            "loss: 2.747e+02\n",
            "gradient 2 norm: 2.185e+02\n",
            "--- epoch 51\n",
            "loss: 2.722e+02\n",
            "gradient 2 norm: 2.138e+02\n",
            "--- epoch 52\n",
            "loss: 2.709e+02\n",
            "gradient 2 norm: 2.140e+02\n",
            "--- epoch 53\n",
            "loss: 2.683e+02\n",
            "gradient 2 norm: 2.144e+02\n",
            "--- epoch 54\n",
            "loss: 2.556e+02\n",
            "gradient 2 norm: 2.065e+02\n",
            "--- epoch 55\n",
            "loss: 2.455e+02\n",
            "gradient 2 norm: 1.931e+02\n",
            "--- epoch 56\n",
            "loss: 2.283e+02\n",
            "gradient 2 norm: 1.716e+02\n",
            "--- epoch 57\n",
            "loss: 2.242e+02\n",
            "gradient 2 norm: 1.674e+02\n",
            "--- epoch 58\n",
            "loss: 2.228e+02\n",
            "gradient 2 norm: 1.667e+02\n",
            "--- epoch 59\n",
            "loss: 2.201e+02\n",
            "gradient 2 norm: 1.664e+02\n",
            "--- epoch 60\n",
            "loss: 2.115e+02\n",
            "gradient 2 norm: 1.623e+02\n",
            "--- epoch 61\n",
            "loss: 2.013e+02\n",
            "gradient 2 norm: 1.477e+02\n",
            "--- epoch 62\n",
            "loss: 1.913e+02\n",
            "gradient 2 norm: 1.286e+02\n",
            "--- epoch 63\n",
            "loss: 1.888e+02\n",
            "gradient 2 norm: 1.225e+02\n",
            "--- epoch 64\n",
            "loss: 1.876e+02\n",
            "gradient 2 norm: 1.207e+02\n",
            "--- epoch 65\n",
            "loss: 1.826e+02\n",
            "gradient 2 norm: 1.142e+02\n",
            "--- epoch 66\n",
            "loss: 1.771e+02\n",
            "gradient 2 norm: 1.043e+02\n",
            "--- epoch 67\n",
            "loss: 1.761e+02\n",
            "gradient 2 norm: 1.010e+02\n",
            "--- epoch 68\n",
            "loss: 1.756e+02\n",
            "gradient 2 norm: 1.005e+02\n",
            "--- epoch 69\n",
            "loss: 1.700e+02\n",
            "gradient 2 norm: 8.772e+01\n",
            "--- epoch 70\n",
            "loss: 1.668e+02\n",
            "gradient 2 norm: 7.933e+01\n",
            "--- epoch 71\n",
            "loss: 1.666e+02\n",
            "gradient 2 norm: 7.804e+01\n",
            "--- epoch 72\n",
            "loss: 1.658e+02\n",
            "gradient 2 norm: 7.681e+01\n",
            "--- epoch 73\n",
            "loss: 1.591e+02\n",
            "gradient 2 norm: 6.987e+01\n",
            "--- epoch 74\n",
            "loss: 1.579e+02\n",
            "gradient 2 norm: 6.918e+01\n",
            "--- epoch 75\n",
            "loss: 1.577e+02\n",
            "gradient 2 norm: 6.897e+01\n",
            "--- epoch 76\n",
            "loss: 1.518e+02\n",
            "gradient 2 norm: 6.481e+01\n",
            "--- epoch 77\n",
            "loss: 1.432e+02\n",
            "gradient 2 norm: 7.806e+01\n",
            "--- epoch 78\n",
            "loss: 1.426e+02\n",
            "gradient 2 norm: 7.910e+01\n",
            "--- epoch 79\n",
            "loss: 1.357e+02\n",
            "gradient 2 norm: 1.161e+02\n",
            "--- epoch 80\n",
            "loss: 1.318e+02\n",
            "gradient 2 norm: 1.188e+02\n",
            "--- epoch 81\n",
            "loss: 1.313e+02\n",
            "gradient 2 norm: 1.187e+02\n",
            "--- epoch 82\n",
            "loss: 1.213e+02\n",
            "gradient 2 norm: 9.560e+01\n",
            "--- epoch 83\n",
            "loss: 1.128e+02\n",
            "gradient 2 norm: 8.100e+01\n",
            "--- epoch 84\n",
            "loss: 1.123e+02\n",
            "gradient 2 norm: 7.971e+01\n",
            "--- epoch 85\n",
            "loss: 1.102e+02\n",
            "gradient 2 norm: 7.276e+01\n",
            "--- epoch 86\n",
            "loss: 1.053e+02\n",
            "gradient 2 norm: 5.559e+01\n",
            "--- epoch 87\n",
            "loss: 1.051e+02\n",
            "gradient 2 norm: 5.479e+01\n",
            "--- epoch 88\n",
            "loss: 1.020e+02\n",
            "gradient 2 norm: 4.318e+01\n",
            "--- epoch 89\n",
            "loss: 1.006e+02\n",
            "gradient 2 norm: 3.638e+01\n",
            "--- epoch 90\n",
            "loss: 1.006e+02\n",
            "gradient 2 norm: 3.616e+01\n",
            "--- epoch 91\n",
            "loss: 9.883e+01\n",
            "gradient 2 norm: 2.522e+01\n",
            "--- epoch 92\n",
            "loss: 9.862e+01\n",
            "gradient 2 norm: 2.341e+01\n",
            "--- epoch 93\n",
            "loss: 9.851e+01\n",
            "gradient 2 norm: 2.258e+01\n",
            "--- epoch 94\n",
            "loss: 9.762e+01\n",
            "gradient 2 norm: 1.395e+01\n",
            "--- epoch 95\n",
            "loss: 9.760e+01\n",
            "gradient 2 norm: 1.386e+01\n",
            "--- epoch 96\n",
            "loss: 9.747e+01\n",
            "gradient 2 norm: 1.207e+01\n",
            "--- epoch 97\n",
            "loss: 9.731e+01\n",
            "gradient 2 norm: 9.260e+00\n",
            "--- epoch 98\n",
            "loss: 9.731e+01\n",
            "gradient 2 norm: 9.191e+00\n",
            "--- epoch 99\n",
            "loss: 9.717e+01\n",
            "gradient 2 norm: 6.854e+00\n",
            "--- epoch 100\n",
            "loss: 9.717e+01\n",
            "gradient 2 norm: 6.788e+00\n",
            "--- epoch 101\n",
            "loss: 9.712e+01\n",
            "gradient 2 norm: 6.660e+00\n",
            "--- epoch 102\n",
            "loss: 9.710e+01\n",
            "gradient 2 norm: 6.385e+00\n",
            "--- epoch 103\n",
            "loss: 9.709e+01\n",
            "gradient 2 norm: 6.310e+00\n",
            "--- epoch 104\n",
            "loss: 9.702e+01\n",
            "gradient 2 norm: 5.543e+00\n",
            "--- epoch 105\n",
            "loss: 9.702e+01\n",
            "gradient 2 norm: 5.562e+00\n",
            "--- epoch 106\n",
            "loss: 9.698e+01\n",
            "gradient 2 norm: 9.293e+00\n",
            "--- epoch 107\n",
            "loss: 9.697e+01\n",
            "gradient 2 norm: 9.335e+00\n",
            "--- epoch 108\n",
            "loss: 9.688e+01\n",
            "gradient 2 norm: 6.537e+00\n",
            "--- epoch 109\n",
            "loss: 9.687e+01\n",
            "gradient 2 norm: 6.285e+00\n",
            "--- epoch 110\n",
            "loss: 9.685e+01\n",
            "gradient 2 norm: 6.701e+00\n",
            "--- epoch 111\n",
            "loss: 9.664e+01\n",
            "gradient 2 norm: 1.083e+01\n",
            "--- epoch 112\n",
            "loss: 9.664e+01\n",
            "gradient 2 norm: 1.090e+01\n",
            "--- epoch 113\n",
            "loss: 9.641e+01\n",
            "gradient 2 norm: 1.030e+01\n",
            "--- epoch 114\n",
            "loss: 9.632e+01\n",
            "gradient 2 norm: 1.041e+01\n",
            "--- epoch 115\n",
            "loss: 9.626e+01\n",
            "gradient 2 norm: 1.058e+01\n",
            "--- epoch 116\n",
            "loss: 9.604e+01\n",
            "gradient 2 norm: 1.422e+01\n",
            "--- epoch 117\n",
            "loss: 9.603e+01\n",
            "gradient 2 norm: 1.428e+01\n",
            "--- epoch 118\n",
            "loss: 9.595e+01\n",
            "gradient 2 norm: 1.468e+01\n",
            "--- epoch 119\n",
            "loss: 9.590e+01\n",
            "gradient 2 norm: 1.396e+01\n",
            "--- epoch 120\n",
            "loss: 9.562e+01\n",
            "gradient 2 norm: 1.012e+01\n",
            "--- epoch 121\n",
            "loss: 9.561e+01\n",
            "gradient 2 norm: 1.017e+01\n",
            "--- epoch 122\n",
            "loss: 9.526e+01\n",
            "gradient 2 norm: 1.162e+01\n",
            "--- epoch 123\n",
            "loss: 9.526e+01\n",
            "gradient 2 norm: 1.165e+01\n",
            "--- epoch 124\n",
            "loss: 9.490e+01\n",
            "gradient 2 norm: 1.008e+01\n",
            "--- epoch 125\n",
            "loss: 9.485e+01\n",
            "gradient 2 norm: 9.896e+00\n",
            "--- epoch 126\n",
            "loss: 9.472e+01\n",
            "gradient 2 norm: 1.068e+01\n",
            "--- epoch 127\n",
            "loss: 9.465e+01\n",
            "gradient 2 norm: 1.158e+01\n",
            "--- epoch 128\n",
            "loss: 9.441e+01\n",
            "gradient 2 norm: 1.568e+01\n",
            "--- epoch 129\n",
            "loss: 9.436e+01\n",
            "gradient 2 norm: 1.618e+01\n",
            "--- epoch 130\n",
            "loss: 9.413e+01\n",
            "gradient 2 norm: 1.258e+01\n",
            "--- epoch 131\n",
            "loss: 9.411e+01\n",
            "gradient 2 norm: 1.269e+01\n",
            "--- epoch 132\n",
            "loss: 9.377e+01\n",
            "gradient 2 norm: 1.287e+01\n",
            "--- epoch 133\n",
            "loss: 9.344e+01\n",
            "gradient 2 norm: 1.127e+01\n",
            "--- epoch 134\n",
            "loss: 9.334e+01\n",
            "gradient 2 norm: 1.100e+01\n",
            "--- epoch 135\n",
            "loss: 9.305e+01\n",
            "gradient 2 norm: 1.119e+01\n",
            "--- epoch 136\n",
            "loss: 9.281e+01\n",
            "gradient 2 norm: 1.250e+01\n",
            "--- epoch 137\n",
            "loss: 9.249e+01\n",
            "gradient 2 norm: 1.338e+01\n",
            "--- epoch 138\n",
            "loss: 9.229e+01\n",
            "gradient 2 norm: 1.158e+01\n",
            "--- epoch 139\n",
            "loss: 9.204e+01\n",
            "gradient 2 norm: 1.248e+01\n",
            "--- epoch 140\n",
            "loss: 9.177e+01\n",
            "gradient 2 norm: 9.997e+00\n",
            "--- epoch 141\n",
            "loss: 9.158e+01\n",
            "gradient 2 norm: 1.604e+01\n",
            "--- epoch 142\n",
            "loss: 9.147e+01\n",
            "gradient 2 norm: 1.743e+01\n",
            "--- epoch 143\n",
            "loss: 9.104e+01\n",
            "gradient 2 norm: 1.288e+01\n",
            "--- epoch 144\n",
            "loss: 9.088e+01\n",
            "gradient 2 norm: 1.347e+01\n",
            "--- epoch 145\n",
            "loss: 9.061e+01\n",
            "gradient 2 norm: 9.034e+00\n",
            "--- epoch 146\n",
            "loss: 9.046e+01\n",
            "gradient 2 norm: 1.929e+01\n",
            "--- epoch 147\n",
            "loss: 9.022e+01\n",
            "gradient 2 norm: 1.450e+01\n",
            "--- epoch 148\n",
            "loss: 9.011e+01\n",
            "gradient 2 norm: 1.406e+01\n",
            "--- epoch 149\n",
            "loss: 8.984e+01\n",
            "gradient 2 norm: 6.782e+00\n",
            "--- epoch 150\n",
            "loss: 8.964e+01\n",
            "gradient 2 norm: 9.366e+00\n",
            "--- epoch 151\n",
            "loss: 8.941e+01\n",
            "gradient 2 norm: 1.339e+01\n",
            "--- epoch 152\n",
            "loss: 8.907e+01\n",
            "gradient 2 norm: 1.352e+01\n",
            "--- epoch 153\n",
            "loss: 8.884e+01\n",
            "gradient 2 norm: 1.452e+01\n",
            "--- epoch 154\n",
            "loss: 8.865e+01\n",
            "gradient 2 norm: 1.215e+01\n",
            "--- epoch 155\n",
            "loss: 8.849e+01\n",
            "gradient 2 norm: 1.405e+01\n",
            "--- epoch 156\n",
            "loss: 8.815e+01\n",
            "gradient 2 norm: 9.895e+00\n",
            "--- epoch 157\n",
            "loss: 8.796e+01\n",
            "gradient 2 norm: 9.225e+00\n",
            "--- epoch 158\n",
            "loss: 8.769e+01\n",
            "gradient 2 norm: 1.722e+01\n",
            "--- epoch 159\n",
            "loss: 8.757e+01\n",
            "gradient 2 norm: 1.511e+01\n",
            "--- epoch 160\n",
            "loss: 8.720e+01\n",
            "gradient 2 norm: 6.727e+00\n",
            "--- epoch 161\n",
            "loss: 8.702e+01\n",
            "gradient 2 norm: 1.180e+01\n",
            "--- epoch 162\n",
            "loss: 8.676e+01\n",
            "gradient 2 norm: 6.113e+00\n",
            "--- epoch 163\n",
            "loss: 8.644e+01\n",
            "gradient 2 norm: 7.183e+00\n",
            "--- epoch 164\n",
            "loss: 8.624e+01\n",
            "gradient 2 norm: 1.241e+01\n",
            "--- epoch 165\n",
            "loss: 8.606e+01\n",
            "gradient 2 norm: 1.074e+01\n",
            "--- epoch 166\n",
            "loss: 8.589e+01\n",
            "gradient 2 norm: 1.072e+01\n",
            "--- epoch 167\n",
            "loss: 8.577e+01\n",
            "gradient 2 norm: 1.135e+01\n",
            "--- epoch 168\n",
            "loss: 8.563e+01\n",
            "gradient 2 norm: 9.306e+00\n",
            "--- epoch 169\n",
            "loss: 8.544e+01\n",
            "gradient 2 norm: 1.017e+01\n",
            "--- epoch 170\n",
            "loss: 8.522e+01\n",
            "gradient 2 norm: 1.035e+01\n",
            "--- epoch 171\n",
            "loss: 8.503e+01\n",
            "gradient 2 norm: 1.788e+01\n",
            "--- epoch 172\n",
            "loss: 8.479e+01\n",
            "gradient 2 norm: 1.454e+01\n",
            "--- epoch 173\n",
            "loss: 8.467e+01\n",
            "gradient 2 norm: 1.410e+01\n",
            "--- epoch 174\n",
            "loss: 8.439e+01\n",
            "gradient 2 norm: 1.063e+01\n",
            "--- epoch 175\n",
            "loss: 8.407e+01\n",
            "gradient 2 norm: 1.205e+01\n",
            "--- epoch 176\n",
            "loss: 8.373e+01\n",
            "gradient 2 norm: 1.439e+01\n",
            "--- epoch 177\n",
            "loss: 8.355e+01\n",
            "gradient 2 norm: 1.820e+01\n",
            "--- epoch 178\n",
            "loss: 8.319e+01\n",
            "gradient 2 norm: 1.519e+01\n",
            "--- epoch 179\n",
            "loss: 8.286e+01\n",
            "gradient 2 norm: 1.295e+01\n",
            "--- epoch 180\n",
            "loss: 8.264e+01\n",
            "gradient 2 norm: 1.294e+01\n",
            "--- epoch 181\n",
            "loss: 8.242e+01\n",
            "gradient 2 norm: 1.017e+01\n",
            "--- epoch 182\n",
            "loss: 8.225e+01\n",
            "gradient 2 norm: 1.174e+01\n",
            "--- epoch 183\n",
            "loss: 8.189e+01\n",
            "gradient 2 norm: 1.474e+01\n",
            "--- epoch 184\n",
            "loss: 8.161e+01\n",
            "gradient 2 norm: 9.906e+00\n",
            "--- epoch 185\n",
            "loss: 8.143e+01\n",
            "gradient 2 norm: 1.381e+01\n",
            "--- epoch 186\n",
            "loss: 8.138e+01\n",
            "gradient 2 norm: 2.076e+01\n",
            "--- epoch 187\n",
            "loss: 8.098e+01\n",
            "gradient 2 norm: 1.803e+01\n",
            "--- epoch 188\n",
            "loss: 8.069e+01\n",
            "gradient 2 norm: 1.097e+01\n",
            "--- epoch 189\n",
            "loss: 8.045e+01\n",
            "gradient 2 norm: 7.681e+00\n",
            "--- epoch 190\n",
            "loss: 8.027e+01\n",
            "gradient 2 norm: 8.859e+00\n",
            "--- epoch 191\n",
            "loss: 8.007e+01\n",
            "gradient 2 norm: 1.012e+01\n",
            "--- epoch 192\n",
            "loss: 7.982e+01\n",
            "gradient 2 norm: 1.027e+01\n",
            "--- epoch 193\n",
            "loss: 7.943e+01\n",
            "gradient 2 norm: 1.095e+01\n",
            "--- epoch 194\n",
            "loss: 7.908e+01\n",
            "gradient 2 norm: 1.784e+01\n",
            "--- epoch 195\n",
            "loss: 7.905e+01\n",
            "gradient 2 norm: 2.023e+01\n",
            "--- epoch 196\n",
            "loss: 7.866e+01\n",
            "gradient 2 norm: 2.179e+01\n",
            "--- epoch 197\n",
            "loss: 7.841e+01\n",
            "gradient 2 norm: 9.705e+00\n",
            "--- epoch 198\n",
            "loss: 7.828e+01\n",
            "gradient 2 norm: 9.525e+00\n",
            "--- epoch 199\n",
            "loss: 7.810e+01\n",
            "gradient 2 norm: 9.257e+00\n",
            "--- epoch 200\n",
            "loss: 7.795e+01\n",
            "gradient 2 norm: 1.406e+01\n",
            "--- epoch 201\n",
            "loss: 7.779e+01\n",
            "gradient 2 norm: 1.188e+01\n",
            "--- epoch 202\n",
            "loss: 7.761e+01\n",
            "gradient 2 norm: 9.173e+00\n",
            "--- epoch 203\n",
            "loss: 7.743e+01\n",
            "gradient 2 norm: 9.665e+00\n",
            "--- epoch 204\n",
            "loss: 7.726e+01\n",
            "gradient 2 norm: 1.021e+01\n",
            "--- epoch 205\n",
            "loss: 7.692e+01\n",
            "gradient 2 norm: 1.323e+01\n",
            "--- epoch 206\n",
            "loss: 7.675e+01\n",
            "gradient 2 norm: 1.319e+01\n",
            "--- epoch 207\n",
            "loss: 7.632e+01\n",
            "gradient 2 norm: 1.813e+01\n",
            "--- epoch 208\n",
            "loss: 7.602e+01\n",
            "gradient 2 norm: 1.102e+01\n",
            "--- epoch 209\n",
            "loss: 7.578e+01\n",
            "gradient 2 norm: 1.307e+01\n",
            "--- epoch 210\n",
            "loss: 7.554e+01\n",
            "gradient 2 norm: 1.437e+01\n",
            "--- epoch 211\n",
            "loss: 7.536e+01\n",
            "gradient 2 norm: 1.219e+01\n",
            "--- epoch 212\n",
            "loss: 7.505e+01\n",
            "gradient 2 norm: 1.336e+01\n",
            "--- epoch 213\n",
            "loss: 7.478e+01\n",
            "gradient 2 norm: 1.031e+01\n",
            "--- epoch 214\n",
            "loss: 7.468e+01\n",
            "gradient 2 norm: 1.418e+01\n",
            "--- epoch 215\n",
            "loss: 7.437e+01\n",
            "gradient 2 norm: 1.367e+01\n",
            "--- epoch 216\n",
            "loss: 7.414e+01\n",
            "gradient 2 norm: 1.433e+01\n",
            "--- epoch 217\n",
            "loss: 7.402e+01\n",
            "gradient 2 norm: 7.895e+00\n",
            "--- epoch 218\n",
            "loss: 7.383e+01\n",
            "gradient 2 norm: 8.798e+00\n",
            "--- epoch 219\n",
            "loss: 7.366e+01\n",
            "gradient 2 norm: 9.876e+00\n",
            "--- epoch 220\n",
            "loss: 7.340e+01\n",
            "gradient 2 norm: 9.474e+00\n",
            "--- epoch 221\n",
            "loss: 7.306e+01\n",
            "gradient 2 norm: 1.189e+01\n",
            "--- epoch 222\n",
            "loss: 7.287e+01\n",
            "gradient 2 norm: 1.196e+01\n",
            "--- epoch 223\n",
            "loss: 7.244e+01\n",
            "gradient 2 norm: 1.354e+01\n",
            "--- epoch 224\n",
            "loss: 7.221e+01\n",
            "gradient 2 norm: 1.272e+01\n",
            "--- epoch 225\n",
            "loss: 7.177e+01\n",
            "gradient 2 norm: 1.627e+01\n",
            "--- epoch 226\n",
            "loss: 7.149e+01\n",
            "gradient 2 norm: 1.623e+01\n",
            "--- epoch 227\n",
            "loss: 7.129e+01\n",
            "gradient 2 norm: 1.711e+01\n",
            "--- epoch 228\n",
            "loss: 7.085e+01\n",
            "gradient 2 norm: 1.270e+01\n",
            "--- epoch 229\n",
            "loss: 7.056e+01\n",
            "gradient 2 norm: 1.261e+01\n",
            "--- epoch 230\n",
            "loss: 7.031e+01\n",
            "gradient 2 norm: 9.387e+00\n",
            "--- epoch 231\n",
            "loss: 7.013e+01\n",
            "gradient 2 norm: 1.375e+01\n",
            "--- epoch 232\n",
            "loss: 7.001e+01\n",
            "gradient 2 norm: 1.356e+01\n",
            "--- epoch 233\n",
            "loss: 6.993e+01\n",
            "gradient 2 norm: 1.909e+01\n",
            "--- epoch 234\n",
            "loss: 6.971e+01\n",
            "gradient 2 norm: 7.858e+00\n",
            "--- epoch 235\n",
            "loss: 6.957e+01\n",
            "gradient 2 norm: 1.397e+01\n",
            "--- epoch 236\n",
            "loss: 6.934e+01\n",
            "gradient 2 norm: 1.286e+01\n",
            "--- epoch 237\n",
            "loss: 6.902e+01\n",
            "gradient 2 norm: 8.845e+00\n",
            "--- epoch 238\n",
            "loss: 6.884e+01\n",
            "gradient 2 norm: 9.041e+00\n",
            "--- epoch 239\n",
            "loss: 6.860e+01\n",
            "gradient 2 norm: 8.746e+00\n",
            "--- epoch 240\n",
            "loss: 6.835e+01\n",
            "gradient 2 norm: 1.133e+01\n",
            "--- epoch 241\n",
            "loss: 6.821e+01\n",
            "gradient 2 norm: 1.711e+01\n",
            "--- epoch 242\n",
            "loss: 6.793e+01\n",
            "gradient 2 norm: 1.241e+01\n",
            "--- epoch 243\n",
            "loss: 6.770e+01\n",
            "gradient 2 norm: 1.267e+01\n",
            "--- epoch 244\n",
            "loss: 6.737e+01\n",
            "gradient 2 norm: 1.169e+01\n",
            "--- epoch 245\n",
            "loss: 6.719e+01\n",
            "gradient 2 norm: 1.023e+01\n",
            "--- epoch 246\n",
            "loss: 6.703e+01\n",
            "gradient 2 norm: 9.551e+00\n",
            "--- epoch 247\n",
            "loss: 6.689e+01\n",
            "gradient 2 norm: 1.327e+01\n",
            "--- epoch 248\n",
            "loss: 6.668e+01\n",
            "gradient 2 norm: 1.331e+01\n",
            "--- epoch 249\n",
            "loss: 6.643e+01\n",
            "gradient 2 norm: 1.191e+01\n",
            "--- epoch 250\n",
            "loss: 6.619e+01\n",
            "gradient 2 norm: 1.369e+01\n",
            "--- epoch 251\n",
            "loss: 6.593e+01\n",
            "gradient 2 norm: 1.011e+01\n",
            "--- epoch 252\n",
            "loss: 6.564e+01\n",
            "gradient 2 norm: 1.241e+01\n",
            "--- epoch 253\n",
            "loss: 6.540e+01\n",
            "gradient 2 norm: 1.300e+01\n",
            "--- epoch 254\n",
            "loss: 6.511e+01\n",
            "gradient 2 norm: 1.417e+01\n",
            "--- epoch 255\n",
            "loss: 6.492e+01\n",
            "gradient 2 norm: 1.408e+01\n",
            "--- epoch 256\n",
            "loss: 6.460e+01\n",
            "gradient 2 norm: 1.390e+01\n",
            "--- epoch 257\n",
            "loss: 6.434e+01\n",
            "gradient 2 norm: 1.337e+01\n",
            "--- epoch 258\n",
            "loss: 6.410e+01\n",
            "gradient 2 norm: 1.095e+01\n",
            "--- epoch 259\n",
            "loss: 6.396e+01\n",
            "gradient 2 norm: 1.332e+01\n",
            "--- epoch 260\n",
            "loss: 6.373e+01\n",
            "gradient 2 norm: 1.406e+01\n",
            "--- epoch 261\n",
            "loss: 6.356e+01\n",
            "gradient 2 norm: 1.166e+01\n",
            "--- epoch 262\n",
            "loss: 6.341e+01\n",
            "gradient 2 norm: 1.425e+01\n",
            "--- epoch 263\n",
            "loss: 6.316e+01\n",
            "gradient 2 norm: 1.053e+01\n",
            "--- epoch 264\n",
            "loss: 6.287e+01\n",
            "gradient 2 norm: 1.161e+01\n",
            "--- epoch 265\n",
            "loss: 6.268e+01\n",
            "gradient 2 norm: 1.162e+01\n",
            "--- epoch 266\n",
            "loss: 6.243e+01\n",
            "gradient 2 norm: 1.453e+01\n",
            "--- epoch 267\n",
            "loss: 6.211e+01\n",
            "gradient 2 norm: 1.093e+01\n",
            "--- epoch 268\n",
            "loss: 6.194e+01\n",
            "gradient 2 norm: 1.401e+01\n",
            "--- epoch 269\n",
            "loss: 6.164e+01\n",
            "gradient 2 norm: 1.050e+01\n",
            "--- epoch 270\n",
            "loss: 6.140e+01\n",
            "gradient 2 norm: 9.581e+00\n",
            "--- epoch 271\n",
            "loss: 6.120e+01\n",
            "gradient 2 norm: 1.697e+01\n",
            "--- epoch 272\n",
            "loss: 6.096e+01\n",
            "gradient 2 norm: 1.318e+01\n",
            "--- epoch 273\n",
            "loss: 6.067e+01\n",
            "gradient 2 norm: 1.148e+01\n",
            "--- epoch 274\n",
            "loss: 6.050e+01\n",
            "gradient 2 norm: 1.521e+01\n",
            "--- epoch 275\n",
            "loss: 6.025e+01\n",
            "gradient 2 norm: 1.016e+01\n",
            "--- epoch 276\n",
            "loss: 5.999e+01\n",
            "gradient 2 norm: 1.403e+01\n",
            "--- epoch 277\n",
            "loss: 5.979e+01\n",
            "gradient 2 norm: 1.560e+01\n",
            "--- epoch 278\n",
            "loss: 5.943e+01\n",
            "gradient 2 norm: 7.975e+00\n",
            "--- epoch 279\n",
            "loss: 5.912e+01\n",
            "gradient 2 norm: 8.708e+00\n",
            "--- epoch 280\n",
            "loss: 5.889e+01\n",
            "gradient 2 norm: 1.062e+01\n",
            "--- epoch 281\n",
            "loss: 5.852e+01\n",
            "gradient 2 norm: 1.303e+01\n",
            "--- epoch 282\n",
            "loss: 5.815e+01\n",
            "gradient 2 norm: 9.285e+00\n",
            "--- epoch 283\n",
            "loss: 5.774e+01\n",
            "gradient 2 norm: 1.145e+01\n",
            "--- epoch 284\n",
            "loss: 5.760e+01\n",
            "gradient 2 norm: 1.358e+01\n",
            "--- epoch 285\n",
            "loss: 5.732e+01\n",
            "gradient 2 norm: 1.414e+01\n",
            "--- epoch 286\n",
            "loss: 5.695e+01\n",
            "gradient 2 norm: 1.179e+01\n",
            "--- epoch 287\n",
            "loss: 5.672e+01\n",
            "gradient 2 norm: 9.994e+00\n",
            "--- epoch 288\n",
            "loss: 5.637e+01\n",
            "gradient 2 norm: 8.956e+00\n",
            "--- epoch 289\n",
            "loss: 5.613e+01\n",
            "gradient 2 norm: 1.215e+01\n",
            "--- epoch 290\n",
            "loss: 5.589e+01\n",
            "gradient 2 norm: 1.576e+01\n",
            "--- epoch 291\n",
            "loss: 5.564e+01\n",
            "gradient 2 norm: 1.209e+01\n",
            "--- epoch 292\n",
            "loss: 5.525e+01\n",
            "gradient 2 norm: 1.238e+01\n",
            "--- epoch 293\n",
            "loss: 5.490e+01\n",
            "gradient 2 norm: 1.403e+01\n",
            "--- epoch 294\n",
            "loss: 5.472e+01\n",
            "gradient 2 norm: 1.391e+01\n",
            "--- epoch 295\n",
            "loss: 5.458e+01\n",
            "gradient 2 norm: 1.297e+01\n",
            "--- epoch 296\n",
            "loss: 5.419e+01\n",
            "gradient 2 norm: 1.131e+01\n",
            "--- epoch 297\n",
            "loss: 5.386e+01\n",
            "gradient 2 norm: 1.225e+01\n",
            "--- epoch 298\n",
            "loss: 5.359e+01\n",
            "gradient 2 norm: 1.266e+01\n",
            "--- epoch 299\n",
            "loss: 5.345e+01\n",
            "gradient 2 norm: 1.250e+01\n",
            "--- epoch 300\n",
            "loss: 5.324e+01\n",
            "gradient 2 norm: 1.796e+01\n",
            "--- epoch 301\n",
            "loss: 5.301e+01\n",
            "gradient 2 norm: 9.851e+00\n",
            "--- epoch 302\n",
            "loss: 5.283e+01\n",
            "gradient 2 norm: 1.079e+01\n",
            "--- epoch 303\n",
            "loss: 5.260e+01\n",
            "gradient 2 norm: 1.294e+01\n",
            "--- epoch 304\n",
            "loss: 5.228e+01\n",
            "gradient 2 norm: 1.559e+01\n",
            "--- epoch 305\n",
            "loss: 5.199e+01\n",
            "gradient 2 norm: 1.469e+01\n",
            "--- epoch 306\n",
            "loss: 5.169e+01\n",
            "gradient 2 norm: 1.299e+01\n",
            "--- epoch 307\n",
            "loss: 5.142e+01\n",
            "gradient 2 norm: 1.134e+01\n",
            "--- epoch 308\n",
            "loss: 5.113e+01\n",
            "gradient 2 norm: 1.388e+01\n",
            "--- epoch 309\n",
            "loss: 5.078e+01\n",
            "gradient 2 norm: 1.954e+01\n",
            "--- epoch 310\n",
            "loss: 5.053e+01\n",
            "gradient 2 norm: 1.737e+01\n",
            "--- epoch 311\n",
            "loss: 5.021e+01\n",
            "gradient 2 norm: 1.419e+01\n",
            "--- epoch 312\n",
            "loss: 5.001e+01\n",
            "gradient 2 norm: 1.374e+01\n",
            "--- epoch 313\n",
            "loss: 4.978e+01\n",
            "gradient 2 norm: 9.989e+00\n",
            "--- epoch 314\n",
            "loss: 4.945e+01\n",
            "gradient 2 norm: 1.431e+01\n",
            "--- epoch 315\n",
            "loss: 4.935e+01\n",
            "gradient 2 norm: 1.505e+01\n",
            "--- epoch 316\n",
            "loss: 4.901e+01\n",
            "gradient 2 norm: 1.536e+01\n",
            "--- epoch 317\n",
            "loss: 4.874e+01\n",
            "gradient 2 norm: 9.241e+00\n",
            "--- epoch 318\n",
            "loss: 4.843e+01\n",
            "gradient 2 norm: 1.172e+01\n",
            "--- epoch 319\n",
            "loss: 4.816e+01\n",
            "gradient 2 norm: 1.466e+01\n",
            "--- epoch 320\n",
            "loss: 4.779e+01\n",
            "gradient 2 norm: 1.193e+01\n",
            "--- epoch 321\n",
            "loss: 4.759e+01\n",
            "gradient 2 norm: 1.029e+01\n",
            "--- epoch 322\n",
            "loss: 4.737e+01\n",
            "gradient 2 norm: 1.611e+01\n",
            "--- epoch 323\n",
            "loss: 4.713e+01\n",
            "gradient 2 norm: 1.253e+01\n",
            "--- epoch 324\n",
            "loss: 4.693e+01\n",
            "gradient 2 norm: 2.007e+01\n",
            "--- epoch 325\n",
            "loss: 4.648e+01\n",
            "gradient 2 norm: 1.498e+01\n",
            "--- epoch 326\n",
            "loss: 4.613e+01\n",
            "gradient 2 norm: 9.893e+00\n",
            "--- epoch 327\n",
            "loss: 4.592e+01\n",
            "gradient 2 norm: 1.074e+01\n",
            "--- epoch 328\n",
            "loss: 4.560e+01\n",
            "gradient 2 norm: 1.207e+01\n",
            "--- epoch 329\n",
            "loss: 4.541e+01\n",
            "gradient 2 norm: 1.315e+01\n",
            "--- epoch 330\n",
            "loss: 4.529e+01\n",
            "gradient 2 norm: 1.796e+01\n",
            "--- epoch 331\n",
            "loss: 4.498e+01\n",
            "gradient 2 norm: 1.868e+01\n",
            "--- epoch 332\n",
            "loss: 4.481e+01\n",
            "gradient 2 norm: 1.897e+01\n",
            "--- epoch 333\n",
            "loss: 4.434e+01\n",
            "gradient 2 norm: 1.577e+01\n",
            "--- epoch 334\n",
            "loss: 4.412e+01\n",
            "gradient 2 norm: 1.684e+01\n",
            "--- epoch 335\n",
            "loss: 4.397e+01\n",
            "gradient 2 norm: 9.351e+00\n",
            "--- epoch 336\n",
            "loss: 4.382e+01\n",
            "gradient 2 norm: 8.901e+00\n",
            "--- epoch 337\n",
            "loss: 4.366e+01\n",
            "gradient 2 norm: 1.059e+01\n",
            "--- epoch 338\n",
            "loss: 4.341e+01\n",
            "gradient 2 norm: 1.453e+01\n",
            "--- epoch 339\n",
            "loss: 4.303e+01\n",
            "gradient 2 norm: 1.302e+01\n",
            "--- epoch 340\n",
            "loss: 4.272e+01\n",
            "gradient 2 norm: 1.284e+01\n",
            "--- epoch 341\n",
            "loss: 4.261e+01\n",
            "gradient 2 norm: 1.332e+01\n",
            "--- epoch 342\n",
            "loss: 4.224e+01\n",
            "gradient 2 norm: 1.680e+01\n",
            "--- epoch 343\n",
            "loss: 4.200e+01\n",
            "gradient 2 norm: 1.098e+01\n",
            "--- epoch 344\n",
            "loss: 4.169e+01\n",
            "gradient 2 norm: 1.031e+01\n",
            "--- epoch 345\n",
            "loss: 4.154e+01\n",
            "gradient 2 norm: 1.052e+01\n",
            "--- epoch 346\n",
            "loss: 4.128e+01\n",
            "gradient 2 norm: 1.695e+01\n",
            "--- epoch 347\n",
            "loss: 4.096e+01\n",
            "gradient 2 norm: 9.151e+00\n",
            "--- epoch 348\n",
            "loss: 4.063e+01\n",
            "gradient 2 norm: 1.511e+01\n",
            "--- epoch 349\n",
            "loss: 4.028e+01\n",
            "gradient 2 norm: 9.125e+00\n",
            "--- epoch 350\n",
            "loss: 3.989e+01\n",
            "gradient 2 norm: 8.605e+00\n",
            "--- epoch 351\n",
            "loss: 3.974e+01\n",
            "gradient 2 norm: 1.180e+01\n",
            "--- epoch 352\n",
            "loss: 3.938e+01\n",
            "gradient 2 norm: 1.263e+01\n",
            "--- epoch 353\n",
            "loss: 3.883e+01\n",
            "gradient 2 norm: 8.327e+00\n",
            "--- epoch 354\n",
            "loss: 3.870e+01\n",
            "gradient 2 norm: 8.485e+00\n",
            "--- epoch 355\n",
            "loss: 3.842e+01\n",
            "gradient 2 norm: 1.444e+01\n",
            "--- epoch 356\n",
            "loss: 3.823e+01\n",
            "gradient 2 norm: 2.346e+01\n",
            "--- epoch 357\n",
            "loss: 3.806e+01\n",
            "gradient 2 norm: 2.384e+01\n",
            "--- epoch 358\n",
            "loss: 3.775e+01\n",
            "gradient 2 norm: 1.839e+01\n",
            "--- epoch 359\n",
            "loss: 3.749e+01\n",
            "gradient 2 norm: 1.277e+01\n",
            "--- epoch 360\n",
            "loss: 3.726e+01\n",
            "gradient 2 norm: 6.381e+00\n",
            "--- epoch 361\n",
            "loss: 3.711e+01\n",
            "gradient 2 norm: 7.917e+00\n",
            "--- epoch 362\n",
            "loss: 3.695e+01\n",
            "gradient 2 norm: 1.699e+01\n",
            "--- epoch 363\n",
            "loss: 3.661e+01\n",
            "gradient 2 norm: 1.035e+01\n",
            "--- epoch 364\n",
            "loss: 3.628e+01\n",
            "gradient 2 norm: 6.291e+00\n",
            "--- epoch 365\n",
            "loss: 3.607e+01\n",
            "gradient 2 norm: 9.104e+00\n",
            "--- epoch 366\n",
            "loss: 3.584e+01\n",
            "gradient 2 norm: 1.071e+01\n",
            "--- epoch 367\n",
            "loss: 3.550e+01\n",
            "gradient 2 norm: 1.208e+01\n",
            "--- epoch 368\n",
            "loss: 3.518e+01\n",
            "gradient 2 norm: 1.448e+01\n",
            "--- epoch 369\n",
            "loss: 3.482e+01\n",
            "gradient 2 norm: 1.711e+01\n",
            "--- epoch 370\n",
            "loss: 3.472e+01\n",
            "gradient 2 norm: 2.189e+01\n",
            "--- epoch 371\n",
            "loss: 3.428e+01\n",
            "gradient 2 norm: 1.992e+01\n",
            "--- epoch 372\n",
            "loss: 3.420e+01\n",
            "gradient 2 norm: 2.211e+01\n",
            "--- epoch 373\n",
            "loss: 3.382e+01\n",
            "gradient 2 norm: 1.676e+01\n",
            "--- epoch 374\n",
            "loss: 3.359e+01\n",
            "gradient 2 norm: 1.170e+01\n",
            "--- epoch 375\n",
            "loss: 3.337e+01\n",
            "gradient 2 norm: 1.355e+01\n",
            "--- epoch 376\n",
            "loss: 3.315e+01\n",
            "gradient 2 norm: 1.861e+01\n",
            "--- epoch 377\n",
            "loss: 3.280e+01\n",
            "gradient 2 norm: 1.547e+01\n",
            "--- epoch 378\n",
            "loss: 3.259e+01\n",
            "gradient 2 norm: 1.416e+01\n",
            "--- epoch 379\n",
            "loss: 3.223e+01\n",
            "gradient 2 norm: 1.925e+01\n",
            "--- epoch 380\n",
            "loss: 3.201e+01\n",
            "gradient 2 norm: 1.643e+01\n",
            "--- epoch 381\n",
            "loss: 3.177e+01\n",
            "gradient 2 norm: 2.281e+01\n",
            "--- epoch 382\n",
            "loss: 3.128e+01\n",
            "gradient 2 norm: 1.213e+01\n",
            "--- epoch 383\n",
            "loss: 3.108e+01\n",
            "gradient 2 norm: 1.481e+01\n",
            "--- epoch 384\n",
            "loss: 3.076e+01\n",
            "gradient 2 norm: 1.169e+01\n",
            "--- epoch 385\n",
            "loss: 3.046e+01\n",
            "gradient 2 norm: 1.067e+01\n",
            "--- epoch 386\n",
            "loss: 3.028e+01\n",
            "gradient 2 norm: 1.095e+01\n",
            "--- epoch 387\n",
            "loss: 2.996e+01\n",
            "gradient 2 norm: 1.500e+01\n",
            "--- epoch 388\n",
            "loss: 2.979e+01\n",
            "gradient 2 norm: 1.981e+01\n",
            "--- epoch 389\n",
            "loss: 2.928e+01\n",
            "gradient 2 norm: 1.378e+01\n",
            "--- epoch 390\n",
            "loss: 2.911e+01\n",
            "gradient 2 norm: 1.817e+01\n",
            "--- epoch 391\n",
            "loss: 2.880e+01\n",
            "gradient 2 norm: 7.746e+00\n",
            "--- epoch 392\n",
            "loss: 2.860e+01\n",
            "gradient 2 norm: 6.595e+00\n",
            "--- epoch 393\n",
            "loss: 2.836e+01\n",
            "gradient 2 norm: 9.817e+00\n",
            "--- epoch 394\n",
            "loss: 2.805e+01\n",
            "gradient 2 norm: 1.293e+01\n",
            "--- epoch 395\n",
            "loss: 2.760e+01\n",
            "gradient 2 norm: 1.200e+01\n",
            "--- epoch 396\n",
            "loss: 2.740e+01\n",
            "gradient 2 norm: 1.052e+01\n",
            "--- epoch 397\n",
            "loss: 2.710e+01\n",
            "gradient 2 norm: 2.057e+01\n",
            "--- epoch 398\n",
            "loss: 2.667e+01\n",
            "gradient 2 norm: 1.668e+01\n",
            "--- epoch 399\n",
            "loss: 2.645e+01\n",
            "gradient 2 norm: 9.710e+00\n",
            "--- epoch 400\n",
            "loss: 2.626e+01\n",
            "gradient 2 norm: 9.378e+00\n",
            "--- epoch 401\n",
            "loss: 2.597e+01\n",
            "gradient 2 norm: 1.109e+01\n",
            "--- epoch 402\n",
            "loss: 2.566e+01\n",
            "gradient 2 norm: 1.189e+01\n",
            "--- epoch 403\n",
            "loss: 2.535e+01\n",
            "gradient 2 norm: 1.215e+01\n",
            "--- epoch 404\n",
            "loss: 2.506e+01\n",
            "gradient 2 norm: 1.266e+01\n",
            "--- epoch 405\n",
            "loss: 2.481e+01\n",
            "gradient 2 norm: 1.999e+01\n",
            "--- epoch 406\n",
            "loss: 2.446e+01\n",
            "gradient 2 norm: 9.921e+00\n",
            "--- epoch 407\n",
            "loss: 2.427e+01\n",
            "gradient 2 norm: 9.730e+00\n",
            "--- epoch 408\n",
            "loss: 2.397e+01\n",
            "gradient 2 norm: 1.425e+01\n",
            "--- epoch 409\n",
            "loss: 2.369e+01\n",
            "gradient 2 norm: 1.243e+01\n",
            "--- epoch 410\n",
            "loss: 2.345e+01\n",
            "gradient 2 norm: 1.401e+01\n",
            "--- epoch 411\n",
            "loss: 2.312e+01\n",
            "gradient 2 norm: 1.482e+01\n",
            "--- epoch 412\n",
            "loss: 2.282e+01\n",
            "gradient 2 norm: 1.576e+01\n",
            "--- epoch 413\n",
            "loss: 2.256e+01\n",
            "gradient 2 norm: 1.242e+01\n",
            "--- epoch 414\n",
            "loss: 2.218e+01\n",
            "gradient 2 norm: 2.322e+01\n",
            "--- epoch 415\n",
            "loss: 2.192e+01\n",
            "gradient 2 norm: 1.692e+01\n",
            "--- epoch 416\n",
            "loss: 2.164e+01\n",
            "gradient 2 norm: 2.138e+01\n",
            "--- epoch 417\n",
            "loss: 2.146e+01\n",
            "gradient 2 norm: 1.939e+01\n",
            "--- epoch 418\n",
            "loss: 2.113e+01\n",
            "gradient 2 norm: 1.300e+01\n",
            "--- epoch 419\n",
            "loss: 2.096e+01\n",
            "gradient 2 norm: 1.335e+01\n",
            "--- epoch 420\n",
            "loss: 2.061e+01\n",
            "gradient 2 norm: 1.256e+01\n",
            "--- epoch 421\n",
            "loss: 2.039e+01\n",
            "gradient 2 norm: 1.490e+01\n",
            "--- epoch 422\n",
            "loss: 2.012e+01\n",
            "gradient 2 norm: 1.441e+01\n",
            "--- epoch 423\n",
            "loss: 1.980e+01\n",
            "gradient 2 norm: 1.144e+01\n",
            "--- epoch 424\n",
            "loss: 1.959e+01\n",
            "gradient 2 norm: 1.661e+01\n",
            "--- epoch 425\n",
            "loss: 1.930e+01\n",
            "gradient 2 norm: 1.556e+01\n",
            "--- epoch 426\n",
            "loss: 1.905e+01\n",
            "gradient 2 norm: 2.289e+01\n",
            "--- epoch 427\n",
            "loss: 1.870e+01\n",
            "gradient 2 norm: 1.855e+01\n",
            "--- epoch 428\n",
            "loss: 1.845e+01\n",
            "gradient 2 norm: 1.449e+01\n",
            "--- epoch 429\n",
            "loss: 1.812e+01\n",
            "gradient 2 norm: 1.271e+01\n",
            "--- epoch 430\n",
            "loss: 1.794e+01\n",
            "gradient 2 norm: 1.462e+01\n",
            "--- epoch 431\n",
            "loss: 1.766e+01\n",
            "gradient 2 norm: 1.413e+01\n",
            "--- epoch 432\n",
            "loss: 1.742e+01\n",
            "gradient 2 norm: 1.767e+01\n",
            "--- epoch 433\n",
            "loss: 1.707e+01\n",
            "gradient 2 norm: 1.986e+01\n",
            "--- epoch 434\n",
            "loss: 1.684e+01\n",
            "gradient 2 norm: 1.122e+01\n",
            "--- epoch 435\n",
            "loss: 1.659e+01\n",
            "gradient 2 norm: 1.549e+01\n",
            "--- epoch 436\n",
            "loss: 1.636e+01\n",
            "gradient 2 norm: 1.235e+01\n",
            "--- epoch 437\n",
            "loss: 1.609e+01\n",
            "gradient 2 norm: 1.500e+01\n",
            "--- epoch 438\n",
            "loss: 1.573e+01\n",
            "gradient 2 norm: 1.305e+01\n",
            "--- epoch 439\n",
            "loss: 1.544e+01\n",
            "gradient 2 norm: 1.305e+01\n",
            "--- epoch 440\n",
            "loss: 1.525e+01\n",
            "gradient 2 norm: 1.927e+01\n",
            "--- epoch 441\n",
            "loss: 1.482e+01\n",
            "gradient 2 norm: 1.503e+01\n",
            "--- epoch 442\n",
            "loss: 1.454e+01\n",
            "gradient 2 norm: 1.286e+01\n",
            "--- epoch 443\n",
            "loss: 1.420e+01\n",
            "gradient 2 norm: 1.049e+01\n",
            "--- epoch 444\n",
            "loss: 1.395e+01\n",
            "gradient 2 norm: 1.043e+01\n",
            "--- epoch 445\n",
            "loss: 1.375e+01\n",
            "gradient 2 norm: 2.372e+01\n",
            "--- epoch 446\n",
            "loss: 1.359e+01\n",
            "gradient 2 norm: 2.008e+01\n",
            "--- epoch 447\n",
            "loss: 1.323e+01\n",
            "gradient 2 norm: 1.956e+01\n",
            "--- epoch 448\n",
            "loss: 1.291e+01\n",
            "gradient 2 norm: 1.287e+01\n",
            "--- epoch 449\n",
            "loss: 1.269e+01\n",
            "gradient 2 norm: 1.440e+01\n",
            "--- epoch 450\n",
            "loss: 1.238e+01\n",
            "gradient 2 norm: 1.051e+01\n",
            "--- epoch 451\n",
            "loss: 1.214e+01\n",
            "gradient 2 norm: 1.012e+01\n",
            "--- epoch 452\n",
            "loss: 1.205e+01\n",
            "gradient 2 norm: 2.317e+01\n",
            "--- epoch 453\n",
            "loss: 1.179e+01\n",
            "gradient 2 norm: 1.802e+01\n",
            "--- epoch 454\n",
            "loss: 1.144e+01\n",
            "gradient 2 norm: 1.215e+01\n",
            "--- epoch 455\n",
            "loss: 1.113e+01\n",
            "gradient 2 norm: 5.519e+00\n",
            "--- epoch 456\n",
            "loss: 1.085e+01\n",
            "gradient 2 norm: 1.548e+01\n",
            "--- epoch 457\n",
            "loss: 1.053e+01\n",
            "gradient 2 norm: 1.107e+01\n",
            "--- epoch 458\n",
            "loss: 1.011e+01\n",
            "gradient 2 norm: 6.702e+00\n",
            "--- epoch 459\n",
            "loss: 1.002e+01\n",
            "gradient 2 norm: 7.162e+00\n",
            "--- epoch 460\n",
            "loss: 9.763e+00\n",
            "gradient 2 norm: 7.979e+00\n",
            "--- epoch 461\n",
            "loss: 9.524e+00\n",
            "gradient 2 norm: 9.827e+00\n",
            "--- epoch 462\n",
            "loss: 9.079e+00\n",
            "gradient 2 norm: 1.435e+01\n",
            "--- epoch 463\n",
            "loss: 8.751e+00\n",
            "gradient 2 norm: 1.289e+01\n",
            "--- epoch 464\n",
            "loss: 8.401e+00\n",
            "gradient 2 norm: 1.253e+01\n",
            "--- epoch 465\n",
            "loss: 8.247e+00\n",
            "gradient 2 norm: 1.350e+01\n",
            "--- epoch 466\n",
            "loss: 7.948e+00\n",
            "gradient 2 norm: 1.564e+01\n",
            "--- epoch 467\n",
            "loss: 7.517e+00\n",
            "gradient 2 norm: 1.006e+01\n",
            "--- epoch 468\n",
            "loss: 7.145e+00\n",
            "gradient 2 norm: 1.184e+01\n",
            "--- epoch 469\n",
            "loss: 6.988e+00\n",
            "gradient 2 norm: 1.488e+01\n",
            "--- epoch 470\n",
            "loss: 6.617e+00\n",
            "gradient 2 norm: 9.579e+00\n",
            "--- epoch 471\n",
            "loss: 6.163e+00\n",
            "gradient 2 norm: 1.299e+01\n",
            "--- epoch 472\n",
            "loss: 5.827e+00\n",
            "gradient 2 norm: 1.498e+01\n",
            "--- epoch 473\n",
            "loss: 5.671e+00\n",
            "gradient 2 norm: 1.293e+01\n",
            "--- epoch 474\n",
            "loss: 5.249e+00\n",
            "gradient 2 norm: 1.174e+01\n",
            "--- epoch 475\n",
            "loss: 5.029e+00\n",
            "gradient 2 norm: 1.590e+01\n",
            "--- epoch 476\n",
            "loss: 4.805e+00\n",
            "gradient 2 norm: 1.797e+01\n",
            "--- epoch 477\n",
            "loss: 4.460e+00\n",
            "gradient 2 norm: 1.980e+01\n",
            "--- epoch 478\n",
            "loss: 4.259e+00\n",
            "gradient 2 norm: 2.068e+01\n",
            "--- epoch 479\n",
            "loss: 3.887e+00\n",
            "gradient 2 norm: 1.070e+01\n",
            "--- epoch 480\n",
            "loss: 3.748e+00\n",
            "gradient 2 norm: 9.357e+00\n",
            "--- epoch 481\n",
            "loss: 3.483e+00\n",
            "gradient 2 norm: 2.105e+01\n",
            "--- epoch 482\n",
            "loss: 3.179e+00\n",
            "gradient 2 norm: 1.348e+01\n",
            "--- epoch 483\n",
            "loss: 2.896e+00\n",
            "gradient 2 norm: 1.484e+01\n",
            "--- epoch 484\n",
            "loss: 2.605e+00\n",
            "gradient 2 norm: 1.300e+01\n",
            "--- epoch 485\n",
            "loss: 2.321e+00\n",
            "gradient 2 norm: 1.236e+01\n",
            "--- epoch 486\n",
            "loss: 2.046e+00\n",
            "gradient 2 norm: 1.167e+01\n",
            "--- epoch 487\n",
            "loss: 1.793e+00\n",
            "gradient 2 norm: 1.668e+01\n",
            "--- epoch 488\n",
            "loss: 1.523e+00\n",
            "gradient 2 norm: 1.146e+01\n",
            "--- epoch 489\n",
            "loss: 1.344e+00\n",
            "gradient 2 norm: 1.391e+01\n",
            "--- epoch 490\n",
            "loss: 1.109e+00\n",
            "gradient 2 norm: 9.963e+00\n",
            "--- epoch 491\n",
            "loss: 8.993e-01\n",
            "gradient 2 norm: 9.995e+00\n",
            "--- epoch 492\n",
            "loss: 7.389e-01\n",
            "gradient 2 norm: 1.408e+01\n",
            "--- epoch 493\n",
            "loss: 6.824e-01\n",
            "gradient 2 norm: 1.513e+01\n",
            "--- epoch 494\n",
            "loss: 5.157e-01\n",
            "gradient 2 norm: 1.892e+01\n",
            "--- epoch 495\n",
            "loss: 3.927e-01\n",
            "gradient 2 norm: 1.111e+01\n",
            "--- epoch 496\n",
            "loss: 3.129e-01\n",
            "gradient 2 norm: 8.755e+00\n",
            "--- epoch 497\n",
            "loss: 2.503e-01\n",
            "gradient 2 norm: 5.600e+00\n",
            "--- epoch 498\n",
            "loss: 2.074e-01\n",
            "gradient 2 norm: 7.004e+00\n",
            "--- epoch 499\n",
            "loss: 1.461e-01\n",
            "gradient 2 norm: 4.087e+00\n",
            "--- epoch 500\n",
            "loss: 9.524e-02\n",
            "gradient 2 norm: 5.526e+00\n",
            "--- epoch 501\n",
            "loss: 5.533e-02\n",
            "gradient 2 norm: 3.619e+00\n",
            "--- epoch 502\n",
            "loss: 3.104e-02\n",
            "gradient 2 norm: 3.046e+00\n",
            "--- epoch 503\n",
            "loss: 1.928e-02\n",
            "gradient 2 norm: 3.780e+00\n",
            "--- epoch 504\n",
            "loss: 1.058e-02\n",
            "gradient 2 norm: 1.920e+00\n",
            "--- epoch 505\n",
            "loss: 4.993e-03\n",
            "gradient 2 norm: 1.973e+00\n",
            "--- epoch 506\n",
            "loss: 1.685e-03\n",
            "gradient 2 norm: 8.937e-01\n",
            "--- epoch 507\n",
            "loss: 4.112e-04\n",
            "gradient 2 norm: 4.872e-01\n",
            "--- epoch 508\n",
            "loss: 4.769e-05\n",
            "gradient 2 norm: 2.550e-01\n",
            "--- epoch 509\n",
            "loss: 7.217e-06\n",
            "gradient 2 norm: 1.016e-01\n",
            "--- epoch 510\n",
            "loss: 2.436e-06\n",
            "gradient 2 norm: 5.796e-02\n",
            "--- epoch 511\n",
            "loss: 3.804e-07\n",
            "gradient 2 norm: 2.918e-02\n",
            "--- epoch 512\n",
            "loss: 1.147e-07\n",
            "gradient 2 norm: 1.510e-02\n",
            "--- epoch 513\n",
            "loss: 6.839e-09\n",
            "gradient 2 norm: 3.038e-03\n",
            "--- epoch 514\n",
            "loss: 2.159e-09\n",
            "gradient 2 norm: 1.771e-03\n",
            "--- epoch 515\n",
            "loss: 4.061e-11\n",
            "gradient 2 norm: 2.769e-04\n",
            "--- epoch 516\n",
            "loss: 9.461e-12\n",
            "gradient 2 norm: 1.395e-04\n",
            "--- epoch 517\n",
            "loss: 2.092e-13\n",
            "gradient 2 norm: 1.975e-05\n",
            "--- epoch 518\n",
            "loss: 7.484e-14\n",
            "gradient 2 norm: 1.183e-05\n",
            "--- epoch 519\n",
            "loss: 1.409e-15\n",
            "gradient 2 norm: 1.694e-06\n",
            "--- epoch 520\n",
            "loss: 2.292e-16\n",
            "gradient 2 norm: 6.692e-07\n",
            "--- epoch 521\n",
            "loss: 1.727e-17\n",
            "gradient 2 norm: 1.339e-07\n",
            "--- epoch 522\n",
            "loss: 5.349e-18\n",
            "gradient 2 norm: 8.431e-08\n",
            "--- epoch 523\n",
            "loss: 7.389e-20\n",
            "gradient 2 norm: 1.017e-08\n",
            "--- epoch 524\n",
            "loss: 4.396e-20\n",
            "gradient 2 norm: 7.525e-09\n"
          ]
        }
      ],
      "source": [
        "N = 100\n",
        "max_epochs = 1000\n",
        "tol = 1e-8\n",
        "\n",
        "np.random.seed(1)\n",
        "x = np.random.rand(N) * 2\n",
        "dx = grad_jit(x)\n",
        "I = jnp.eye(N)\n",
        "B_inv = I.copy()\n",
        "history = [loss_jit(x)]\n",
        "\n",
        "epoch = 0\n",
        "while epoch < max_epochs and np.linalg.norm(dx) > tol:\n",
        "    epoch += 1\n",
        "    # search direction\n",
        "    p = -B_inv @ dx\n",
        "    # line search\n",
        "    line_search = sp.optimize.line_search(loss_jit, grad_jit, x, p, maxiter=1000)\n",
        "    alpha = line_search[0]\n",
        "    x_new = x + alpha * p\n",
        "    dx_new = grad_jit(x_new)\n",
        "    # Sherman-Morrison update\n",
        "    s = x_new - x\n",
        "    y = dx_new - dx\n",
        "    E = I - np.outer(y, s) / np.inner(y, s)\n",
        "    B_inv = E.T @ B_inv @ E + np.outer(s, s) / np.inner(y, s)\n",
        "    l = loss_jit(x_new)\n",
        "    history.append(l)\n",
        "    x = x_new\n",
        "    dx = dx_new\n",
        "    # print updates\n",
        "    print(\"--- epoch %d\" % epoch)\n",
        "    print(\"loss: %1.3e\" % l)\n",
        "    print(\"gradient 2 norm: %1.3e\" % np.linalg.norm(dx))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2.4811603643377168e-11"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.linalg.norm(x - np.ones(N))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f38c90fc490>]"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.semilogy(history)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
