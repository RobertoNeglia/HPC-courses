## Ex2

library(MASS)

dataset = read.table("fish.txt",header=T)

group = factor(dataset$abundance, levels=c('L', 'H'))   # Species è il nome della colonna del grouping nel dataset
# mettendo i levels sono sicura che l'ordine è quello che penso io

g = 2 # number of groups 


i1 <- which(group=='L')       # rows of group1
i2 <- which(group=='H')    # tante righe quanti gruppi

n1 <- length(i1)
n2 <- length(i2)

n <- n1+n2

dataset_num <- dataset[,1:2]

# gaussianity
load('mcshapiro.test.RData')
data_group1 = dataset_num[i1,]
data_group2 = dataset_num[i2,]

P = c( mcshapiro.test(data_group1)$pvalue, 
       mcshapiro.test(data_group2)$pvalue)
P

# homogeneity

# multivariate
S  <-  cov(dataset_num)
S1 <-  cov(dataset_num[i1,])   # S nel gruppo i = 1..g
S2 <-  cov(dataset_num[i2,])
   # g righe

# Qualitatively:
round(S1,digits=1)
round(S2,digits=1)


# to compare visually
x11()
par(mfrow=c(1,g))
image(S1, col=heat.colors(100),main='Cov. S1', asp=1, axes = FALSE, breaks = quantile(rbind(S1,S2), (0:100)/100, na.rm=TRUE))
image(S2, col=heat.colors(100),main='Cov. S2', asp=1, axes = FALSE, breaks = quantile(rbind(S1,S2), (0:100)/100, na.rm=TRUE))
image(S3, col=heat.colors(100),main='Cov. S3', asp=1, axes = FALSE, breaks = quantile(rbind(S1,S2,S3), (0:100)/100, na.rm=TRUE))



## FDA

m <-  colMeans(dataset_num)   # global mean
m1 <- colMeans(dataset_num[i1,])  # mean in group 1
m2 <- colMeans(dataset_num[i2,])
# m3 <- colMeans(dataset_num[i3,])

S1 <- cov(dataset_num[i1,])
S2 <- cov(dataset_num[i2,])
# S3 <- cov(dataset_num[i3,])
Sp  <- ((n1-1)*S1+(n2-1)*S2)/(n-g)  # estimates of the covariance within groups

# covariance between groups (estimate)
B <- 1/g*(cbind(m1 - m) %*% rbind(m1 - m) +
            cbind(m2 - m) %*% rbind(m2 - m))
B

# covariance within groups (estimate)
Sp

# how many coordinates?
g <- 2
p <- 2
s <- min(g-1,p)
s

# Matrix Sp^(-1/2)
val.Sp <- eigen(Sp)$val
vec.Sp <- eigen(Sp)$vec
invSp.2 <- 1/sqrt(val.Sp[1])*vec.Sp[,1]%*%t(vec.Sp[,1]) + 1/sqrt(val.Sp[2])*vec.Sp[,2]%*%t(vec.Sp[,2])
invSp.2 

# spectral decomposition of Sp^(-1/2) B Sp^(-1/2)
spec.dec <- eigen(invSp.2 %*% B %*% invSp.2)

# first canonical coordinate
a1 <- invSp.2 %*% spec.dec$vec[,1]

# second canonical coordinate
a2 <- invSp.2 %*% spec.dec$vec[,2]




##


cc1.dataset <- as.matrix(dataset_num)%*%a1
cc2.dataset <- as.matrix(dataset_num)%*%a2

coord.cc <- cbind(cc1.dataset,cc2.dataset)

# Compute the coordinates of the mean within groups along the canonical directions
cc.m1 <- c(m1%*%a1, m1%*%a2)
cc.m2 <- c(m2%*%a1, m2%*%a2)
# cc.m3 <- c(m3%*%a1, m3%*%a2)

# Assign data to groups
f.class=rep(0, n)
for(i in 1:n) # for each datum
{
  # Compute the Euclidean distance of the i-th datum from mean within the groups
  dist.m=c(d1=sqrt(sum((coord.cc[i,]-cc.m1)^2)),
           d2=sqrt(sum((coord.cc[i,]-cc.m2)^2)))
  # Assign the datum to the group whose mean is the nearest
  f.class[i]=which.min(dist.m)
}
f.class
table(class.true=group, class.assigned=f.class)



## Parameters
f1 = which(f.class == 1)
f2 = which(f.class == 2)

groupL = dataset_num[f1,]
groupH = dataset_num[f2,]


m1 <- colMeans(groupL)  # mean in group 1
m2 <- colMeans(groupH)
# m3 <- colMeans(dataset_num[i3,])

S1 <- cov(groupL)
S2 <- cov(groupH)


## plot
### We plot the partition generated by the canonical coordinates
color <- group
levels(color) <- c('red','blue')  # g colori

x11()
plot(cc1.dataset, cc2.dataset, main='Fisher discriminant analysis', xlab='first canonical coordinate', ylab='second canonical coordinate', pch=20, col=as.character(color))
legend("topleft", legend=levels(group), fill=c('red','blue'), cex=.7)

points(cc.m1[1], cc.m1[2], pch=4,col='red' , lwd=2, cex=1.5)
points(cc.m2[1], cc.m2[2], pch=4,col='blue' , lwd=2, cex=1.5)
#points(cc.m3[1], cc.m3[2], pch=4,col='blue' , lwd=2, cex=1.5)

x.cc  <- seq(min(cc1.dataset),max(cc1.dataset),len=200)
y.cc  <- seq(min(cc2.dataset),max(cc2.dataset),len=200)
xy.cc <- expand.grid(cc1=x.cc, cc2=y.cc)

z  <- cbind( sqrt(rowSums(scale(xy.cc,cc.m1,scale=FALSE)^2)), sqrt(rowSums(scale(xy.cc,cc.m2,scale=FALSE)^2)))
z1.cc <- z[,1] - pmin(z[,2])    
z2.cc <- z[,2] - pmin(z[,1])    
# z3.cc <- z[,3] - pmin(z[,1], z[,2])

contour(x.cc, y.cc, matrix(z1.cc, 200), levels=0, drawlabels=F, add=T)
contour(x.cc, y.cc, matrix(z2.cc, 200), levels=0, drawlabels=F, add=T)
#contour(x.cc, y.cc, matrix(z3.cc, 200), levels=0, drawlabels=F, add=T)





## c)


x  <- seq(min(dataset_num[,1]), max(dataset_num[,1]), length=200)
y  <- seq(min(dataset_num[,2]), max(dataset_num[,2]), length=200)
xy <- expand.grid(x=x, y=y)
# Sepal.Length è il nome della prima variabile in dataset



# 2) Use CV to estimate the AER
library(class)
best.k = 0
best.err = 1000
best.model = 0
k_range = seq(1, 20)    # range of k you want to test 
set.seed(19)
for (kk in k_range) {
  KNN.CV = knn.cv(train = dataset_num , cl = group,  k = kk)  
  conf.matrix.CV = table(group , KNN.CV)
  # Computation of the AER_hat
  AER_CV = 0
  for(i in 1:g)
    AER_CV = AER_CV + sum(conf.matrix.CV[i,-i])     # no priors
  AER_CV = AER_CV / n 
  if (AER_CV < best.err){
    best.err = AER_CV
    best.k = kk
    best.model = KNN.CV
  }
}
best.model   # labels predicted by the best model according to CV 
best.k       
best.err     # estimate of the AER using CV

# k = 12



dataset_num = dataset[, 1:2]

k = 12
x  <- seq(min(dataset_num[,1]), max(dataset_num[,1]), length=200)
y  <- seq(min(dataset_num[,2]), max(dataset_num[,2]), length=200)
#                nome_var1  nome_var2
xy <- expand.grid( x = x , y = y)

group = factor(dataset$abundance) # Species è la colonna nel dataset che indica il grouping

# se invece ho più file dove ho diversi gruppi vedi su lda come unirli

## KNN per il plot
knn.grid <- knn(train = dataset_num, test = xy, cl = group, k = k)

z  <- as.numeric(knn.grid)

x11()
#                      
plot(dataset_num, main='Iris.Sepal', xlab='Sepal.Length', ylab='Sepal.Width', pch=20)
points(dataset_num[i1,], col=2, pch=20)
points(dataset_num[i2,], col=3, pch=20)
points(dataset_num[i3,], col=4, pch=20)
legend("topright", legend=levels(group), fill=c(2,3,4))
contour(x, y, matrix(z, 200), levels=c(1.5, 2.5), drawlabels=F, add=T)




# knn sul training

knn.m <- knn(train = dataset_num, test = dataset_num, cl = group, k = k , prob=T)


# Table
n = dim(dataset)[1]
misc <- table(class.true = group, class.assigned = knn.m)

# APER somma i misclassificati e dividi per n
APER = 0
for(i in 1:g)
  APER = APER + sum(misc[i,-i])     # no priors
APER = APER / n 
APER

























